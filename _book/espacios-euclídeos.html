<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5 Espacios Euclídeos | Preguntas y respuestas de Álgebra Lineal</title>
  <meta name="description" content="En este libro vamos a recopilar algunas de las preguntas y dudas más frecuentes en los temas de Álgebra Lineal, con ejemplos resueltos, y acompañados de la teoría necesaria para comprender los resultados." />
  <meta name="generator" content="bookdown 0.16 and GitBook 2.6.7" />

  <meta property="og:title" content="5 Espacios Euclídeos | Preguntas y respuestas de Álgebra Lineal" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="En este libro vamos a recopilar algunas de las preguntas y dudas más frecuentes en los temas de Álgebra Lineal, con ejemplos resueltos, y acompañados de la teoría necesaria para comprender los resultados." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 Espacios Euclídeos | Preguntas y respuestas de Álgebra Lineal" />
  
  <meta name="twitter:description" content="En este libro vamos a recopilar algunas de las preguntas y dudas más frecuentes en los temas de Álgebra Lineal, con ejemplos resueltos, y acompañados de la teoría necesaria para comprender los resultados." />
  

<meta name="author" content="Domingo López" />


<meta name="date" content="2020-05-21" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="diagonalización.html"/>
<link rel="next" href="problems.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Preguntas y respuestas de Álgebra Lineal</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introducción</a></li>
<li class="chapter" data-level="2" data-path="ev.html"><a href="ev.html"><i class="fa fa-check"></i><b>2</b> Espacios Vectoriales</a>
<ul>
<li class="chapter" data-level="2.1" data-path="ev.html"><a href="ev.html#subesp"><i class="fa fa-check"></i><b>2.1</b> Qué es un subespacio vectorial</a></li>
<li class="chapter" data-level="2.2" data-path="ev.html"><a href="ev.html#indep"><i class="fa fa-check"></i><b>2.2</b> Qué es un sistema de vectores linealmente independiente</a></li>
<li class="chapter" data-level="2.3" data-path="ev.html"><a href="ev.html#gen"><i class="fa fa-check"></i><b>2.3</b> Qué es un sistema generador y el subespacio generado por un conjunto de vectores</a></li>
<li class="chapter" data-level="2.4" data-path="ev.html"><a href="ev.html#sistgenabase"><i class="fa fa-check"></i><b>2.4</b> Cómo extraemos una base a partir de un sistema generador de un (sub)espacio vectorial</a></li>
<li class="chapter" data-level="2.5" data-path="ev.html"><a href="ev.html#base"><i class="fa fa-check"></i><b>2.5</b> Cómo encontrar la base (y la dimensión) para un subespacio vectorial</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="ev.html"><a href="ev.html#partiendo-de-las-ecuaciones-paramétricas"><i class="fa fa-check"></i><b>2.5.1</b> Partiendo de las ecuaciones paramétricas</a></li>
<li class="chapter" data-level="2.5.2" data-path="ev.html"><a href="ev.html#partiendo-de-las-ecuaciones-cartesianas"><i class="fa fa-check"></i><b>2.5.2</b> Partiendo de las ecuaciones cartesianas</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="ev.html"><a href="ev.html#param2cartesian"><i class="fa fa-check"></i><b>2.6</b> Cómo convertir entre ecuaciones cartesianas y paramétricas de un subespacio vectorial</a></li>
<li class="chapter" data-level="2.7" data-path="ev.html"><a href="ev.html#interseccion"><i class="fa fa-check"></i><b>2.7</b> Cómo hallar la intersección de dos subespacios vectoriales</a></li>
<li class="chapter" data-level="2.8" data-path="ev.html"><a href="ev.html#union"><i class="fa fa-check"></i><b>2.8</b> ¿Es la unión de subespacios un subespacio?</a></li>
<li class="chapter" data-level="2.9" data-path="ev.html"><a href="ev.html#suma"><i class="fa fa-check"></i><b>2.9</b> Cómo hallar la suma de dos subespacios vectoriales</a></li>
<li class="chapter" data-level="2.10" data-path="ev.html"><a href="ev.html#th-dim"><i class="fa fa-check"></i><b>2.10</b> Qué dice el teorema de la dimensión</a></li>
<li class="chapter" data-level="2.11" data-path="ev.html"><a href="ev.html#supl"><i class="fa fa-check"></i><b>2.11</b> Cómo calcular el subespacio suplementario de uno dado</a></li>
<li class="chapter" data-level="2.12" data-path="ev.html"><a href="ev.html#coord"><i class="fa fa-check"></i><b>2.12</b> Cómo calcular las coordenadas de un vector con respecto a una base dada</a></li>
<li class="chapter" data-level="2.13" data-path="ev.html"><a href="ev.html#cambiobase"><i class="fa fa-check"></i><b>2.13</b> Cómo calcular la matriz de cambio de base entre dos bases de un mismo espacio vectorial</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="apli.html"><a href="apli.html"><i class="fa fa-check"></i><b>3</b> Aplicaciones lineales</a>
<ul>
<li class="chapter" data-level="3.1" data-path="apli.html"><a href="apli.html#prop-apli"><i class="fa fa-check"></i><b>3.1</b> Qué propiedades básicas tienen las aplicaciones lineales</a></li>
<li class="chapter" data-level="3.2" data-path="apli.html"><a href="apli.html#matriz-apli"><i class="fa fa-check"></i><b>3.2</b> Cuál es la matriz asociada a una aplicación lineal en unas bases dadas</a></li>
<li class="chapter" data-level="3.3" data-path="apli.html"><a href="apli.html#cambiobase-apli"><i class="fa fa-check"></i><b>3.3</b> Cómo influye un cambio de base en la matriz asociada a una aplicación lineal</a></li>
<li class="chapter" data-level="3.4" data-path="apli.html"><a href="apli.html#nucleo"><i class="fa fa-check"></i><b>3.4</b> Qué es y cómo determinar el núcleo de una aplicación lineal</a></li>
<li class="chapter" data-level="3.5" data-path="apli.html"><a href="apli.html#inyectividad"><i class="fa fa-check"></i><b>3.5</b> Cómo podemos identificar una aplicación lineal inyectiva</a></li>
<li class="chapter" data-level="3.6" data-path="apli.html"><a href="apli.html#imagen"><i class="fa fa-check"></i><b>3.6</b> Cómo calcular el subespacio imagen de una aplicación lineal</a></li>
<li class="chapter" data-level="3.7" data-path="apli.html"><a href="apli.html#sobrey"><i class="fa fa-check"></i><b>3.7</b> Cómo identificar si una aplicación lineal es sobreyectiva</a></li>
<li class="chapter" data-level="3.8" data-path="apli.html"><a href="apli.html#isomorfismo"><i class="fa fa-check"></i><b>3.8</b> Qué es un isomorfismo</a></li>
<li class="chapter" data-level="3.9" data-path="apli.html"><a href="apli.html#imagenU"><i class="fa fa-check"></i><b>3.9</b> Cómo determinar la imagen de un subespacio vectorial</a></li>
<li class="chapter" data-level="3.10" data-path="apli.html"><a href="apli.html#rango-nulidad"><i class="fa fa-check"></i><b>3.10</b> A qué se llama rango y nulidad de la aplicación lineal</a></li>
<li class="chapter" data-level="3.11" data-path="apli.html"><a href="apli.html#th-dim-nucleo"><i class="fa fa-check"></i><b>3.11</b> Qué dice el teorema de la dimensión para núcleo e imagen</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="diagonalización.html"><a href="diagonalización.html"><i class="fa fa-check"></i><b>4</b> Diagonalización</a>
<ul>
<li class="chapter" data-level="4.1" data-path="diagonalización.html"><a href="diagonalización.html#eigenvalue"><i class="fa fa-check"></i><b>4.1</b> Qué son los autovalores de un endomorfismo y de una matriz</a></li>
<li class="chapter" data-level="4.2" data-path="diagonalización.html"><a href="diagonalización.html#eigenspace"><i class="fa fa-check"></i><b>4.2</b> Cómo calculamos los autovectores asociados a un autovalor</a></li>
<li class="chapter" data-level="4.3" data-path="diagonalización.html"><a href="diagonalización.html#diagonalizable"><i class="fa fa-check"></i><b>4.3</b> Cómo sabemos si un endomorfismo o una matriz es diagonalizable</a></li>
<li class="chapter" data-level="4.4" data-path="diagonalización.html"><a href="diagonalización.html#pot-matrix"><i class="fa fa-check"></i><b>4.4</b> Si una matriz es diagonalizable, cómo podemos hallar sus potencias</a></li>
<li class="chapter" data-level="4.5" data-path="diagonalización.html"><a href="diagonalización.html#th-cayley"><i class="fa fa-check"></i><b>4.5</b> Para qué podemos utilizar el Teorema de Cayley-Hamilton</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="espacios-euclídeos.html"><a href="espacios-euclídeos.html"><i class="fa fa-check"></i><b>5</b> Espacios Euclídeos</a>
<ul>
<li class="chapter" data-level="5.1" data-path="espacios-euclídeos.html"><a href="espacios-euclídeos.html#norm"><i class="fa fa-check"></i><b>5.1</b> Qué son las normas y distancias</a></li>
<li class="chapter" data-level="5.2" data-path="espacios-euclídeos.html"><a href="espacios-euclídeos.html#ortho"><i class="fa fa-check"></i><b>5.2</b> Qué significa el concepto de ortogonalidad</a></li>
<li class="chapter" data-level="5.3" data-path="espacios-euclídeos.html"><a href="espacios-euclídeos.html#compl-ortho"><i class="fa fa-check"></i><b>5.3</b> Qué es el complemento ortogonal de un subespacio</a></li>
<li class="chapter" data-level="5.4" data-path="espacios-euclídeos.html"><a href="espacios-euclídeos.html#proyec"><i class="fa fa-check"></i><b>5.4</b> Cómo calculamos la proyección de un vector sobre un subespacio</a></li>
<li class="chapter" data-level="5.5" data-path="espacios-euclídeos.html"><a href="espacios-euclídeos.html#ortho-basis"><i class="fa fa-check"></i><b>5.5</b> Qué es y qué utilidad tiene una base ortonormal</a></li>
<li class="chapter" data-level="5.6" data-path="espacios-euclídeos.html"><a href="espacios-euclídeos.html#gram-schmidt"><i class="fa fa-check"></i><b>5.6</b> Cómo construimos una base ortonormal</a></li>
<li class="chapter" data-level="5.7" data-path="espacios-euclídeos.html"><a href="espacios-euclídeos.html#ortho-matrix"><i class="fa fa-check"></i><b>5.7</b> Qué es una matriz ortogonal y una aplicación ortogonal</a></li>
<li class="chapter" data-level="5.8" data-path="espacios-euclídeos.html"><a href="espacios-euclídeos.html#diag-ortho"><i class="fa fa-check"></i><b>5.8</b> Qué es la diagonalización ortogonal</a></li>
<li class="chapter" data-level="5.9" data-path="espacios-euclídeos.html"><a href="espacios-euclídeos.html#diag-ortho2"><i class="fa fa-check"></i><b>5.9</b> Qué matrices son diagonalizables ortogonalmente</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="problems.html"><a href="problems.html"><i class="fa fa-check"></i><b>6</b> Problemas Resueltos</a>
<ul>
<li class="chapter" data-level="6.1" data-path="problems.html"><a href="problems.html#prob-ev"><i class="fa fa-check"></i><b>6.1</b> Espacios Vectoriales</a></li>
<li class="chapter" data-level="6.2" data-path="problems.html"><a href="problems.html#prob-apli"><i class="fa fa-check"></i><b>6.2</b> Aplicaciones lineales</a></li>
<li class="chapter" data-level="6.3" data-path="problems.html"><a href="problems.html#prob-diag"><i class="fa fa-check"></i><b>6.3</b> Diagonalización</a></li>
<li class="chapter" data-level="6.4" data-path="problems.html"><a href="problems.html#prob-espeuclideo"><i class="fa fa-check"></i><b>6.4</b> Espacios Euclídeos</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://dominlopez.netlify.app" target="blank">Escrito por Domingo López</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Preguntas y respuestas de Álgebra Lineal</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="espacios-euclídeos" class="section level1" number="5">
<h1 number="5"><span class="header-section-number">5</span> Espacios Euclídeos</h1>
<p>En este capítulo, damos un paso para acercarnos a los conceptos geométricos clásicos de distancias y ángulos, abstrayéndolos en el contexto de los espacios vectoriales.</p>
<p>Para ello, precisaremos de la noción de <em>producto escalar</em>: Una aplicación <span class="math inline">\(g:V\times V\to \mathbb{R}\)</span>, donde <span class="math inline">\(V\)</span> es un espacio vectorial sobre <span class="math inline">\(\mathbb{R}\)</span>, es un <strong>producto escalar</strong> si verifica:</p>
<ul>
<li>Es simétrica: <span class="math inline">\(g(u, v) = g(v, u)\)</span> para todo <span class="math inline">\(u,v\in V\)</span>.</li>
<li>Es bilineal: <span class="math inline">\(g(\alpha u + \beta v, w) = \alpha g(u, w) + \beta g(v, w)\)</span> para todos los <span class="math inline">\(\alpha,\beta\in\mathbb{R}\)</span>, <span class="math inline">\(u,v,w\in V\)</span>. Por simetría, se tiene lo mismo para la linealidad en la segunda componente.</li>
<li>Es definida positiva: <span class="math inline">\(g(v, v) &gt; 0\)</span> para todo <span class="math inline">\(v\in V\setminus\{0\}\)</span>, <span class="math inline">\(g(v, v) = 0\)</span> si, y sólo si <span class="math inline">\(v = 0\)</span>.</li>
</ul>
<p>En resumen, se suele definir un producto escalar como una <em>forma bilineal, simétrica y definida positiva</em>.</p>
<p><strong>Notación</strong>: El producto escalar de dos vectores <span class="math inline">\(u\)</span> y <span class="math inline">\(v\)</span> suele recibir diversas notaciones, aunque las más usadas son <span class="math inline">\(u\cdot v\)</span> y <span class="math inline">\(\langle u, v \rangle\)</span>.</p>
<p>A un espacio vectorial <span class="math inline">\(V\)</span> donde podemos definir un producto vectorial lo llamamos <strong>espacio euclídeo</strong>, y lo solemos denotar mediante el par <span class="math inline">\(\left(V, \langle\cdot,\cdot\rangle\right)\)</span>.</p>
<hr />
<p><strong>Ejemplo</strong></p>
<p>En <span class="math inline">\(\mathbb{R}^n\)</span>, disponemos de un <em>producto escalar usual</em>, de forma que si <span class="math inline">\(u, v\in\mathbb{R}^n\)</span>, entonces
<span class="math display">\[\langle u,v \rangle = u_1v_1+u_2v_2+\ldots+u_nv_n\]</span>
siendo <span class="math inline">\(u_i, v_i\)</span>, <span class="math inline">\(i=1,\ldots,n\)</span> las coordenadas de <span class="math inline">\(u\)</span> y de <span class="math inline">\(v\)</span>, respectivamente, en una base dada (la canónica como caso particular). A este producto vectorial es al que nos referiremos cuando usemos la notación <span class="math inline">\(u\cdot v\)</span>.</p>
<p>Podemos generalizar este producto escalar, definiendo unos pesos <span class="math inline">\(\alpha_i\in\mathbb{R}^{+}\)</span> para cada componente:
<span class="math display">\[\langle u,v \rangle = \alpha_1u_1v_1+\alpha_2u_2v_2+\ldots+\alpha_nu_nv_n\]</span></p>
<p>Podemos construir productos escalares de la siguiente forma: Tomemos una matriz <span class="math inline">\(A\in\mathcal{M}_n(\mathbb{R})\)</span> simétrica y definida positiva. Entonces la aplicación <span class="math inline">\(\langle\cdot,\cdot\rangle:\mathbb{R}^n\times\mathbb{R}^n\to\mathbb{R}\)</span> definida por
<span class="math display">\[\langle u, v \rangle = u^{\text{t}}\ A\ v\]</span>
es un producto escalar. A esta matriz <span class="math inline">\(A\)</span> se le denomina <em>matriz de Gram</em>, y todo producto escalar tiene asociada una. Los dos ejemplos anteriores se correspondían con tomar como <span class="math inline">\(A\)</span> la matriz identidad o una matriz diagonal con elementos positivos <span class="math inline">\(\alpha_i\in\mathbb{R}^{+}\)</span> en la diagonal.</p>
<hr />
<p><strong>¿Qué preguntas vamos a responder en este capítulo?</strong></p>
<ul>
<li><a href="espacios-euclídeos.html#norm">¿Qué son las normas y distancias?</a></li>
<li><a href="espacios-euclídeos.html#ortho">¿Qué significa el concepto de ortogonalidad?</a></li>
<li><a href="espacios-euclídeos.html#compl-ortho">¿Qué es el complemento ortogonal de un subespacio?</a></li>
<li><a href="espacios-euclídeos.html#proyec">¿Cómo calculamos la proyección de un vector sobre un subespacio?</a></li>
<li><a href="espacios-euclídeos.html#ortho-basis">¿Qué es y qué utilidad tiene una base ortonormal?</a></li>
<li><a href="espacios-euclídeos.html#gram-schmidt">¿Cómo construimos una base ortonormal?</a></li>
<li><a href="espacios-euclídeos.html#ortho-matrix">¿Qué es una matriz ortogonal y una aplicación ortogonal?</a></li>
<li><a href="espacios-euclídeos.html#diag-ortho">¿Qué es la diagonalización ortogonal?</a></li>
<li><a href="espacios-euclídeos.html#diag-ortho2">Qué matrices son diagonalizables ortogonalmente</a></li>
</ul>
<div id="norm" class="section level2" number="5.1">
<h2 number="5.1"><span class="header-section-number">5.1</span> Qué son las normas y distancias</h2>
<p>Una <strong>norma</strong> vectorial sobre un espacio <span class="math inline">\(V\)</span> (sobre un cuerpo <span class="math inline">\(\mathbb{K}\)</span>) es un operador que sirve para <em>medir</em> la longitud de un vector (es decir, su distancia al origen), y se define formalmente como una aplicación <span class="math inline">\(\|\cdot\|:V\to\mathbb{R}\)</span> que verifica:</p>
<ul>
<li>Para todo <span class="math inline">\(v\in V\)</span>, <span class="math inline">\(\|v\| &gt; 0\)</span>, con <span class="math inline">\(\|v\| = 0\)</span> si, y solo si, <span class="math inline">\(v = 0\)</span>.</li>
<li>Para todo <span class="math inline">\(c\in\mathbb{K}\)</span>, <span class="math inline">\(v\in V\)</span>, se tiene <span class="math inline">\(\|cv\| = |c|\cdot \|v\|\)</span>.</li>
<li>Para todo <span class="math inline">\(u,v\in V\)</span>, <span class="math inline">\(\|u+v\|\le\|u\|+\|v\|\)</span>. Esta propiedad se llama <em>desigualdad triangular</em> (en un triángulo, la suma de la longitud de dos de sus lados – <span class="math inline">\(\|u\|\)</span> y <span class="math inline">\(\|v\|\)</span> – es siempre menor que la longitud de su otro lado – <span class="math inline">\(\|u+v\|\)</span> – ).</li>
</ul>
<p>Cualquier operador <span class="math inline">\(\|\cdot\|\)</span> que verifique lo anterior es una norma vectorial. Sin embargo, podemos construir normas a partir de un producto escalar:</p>
<blockquote>
<p>Si <span class="math inline">\(\langle\cdot,\cdot\rangle\)</span> es un producto escalar en el espacio <span class="math inline">\(V\)</span>, entonces la aplicación <span class="math inline">\(\|\cdot\|:V\to\mathbb{R}\)</span> dada por <span class="math inline">\(\|v\| = \sqrt{\langle v, v\rangle}\)</span> es una <strong>norma derivada del producto escalar</strong> sobre <span class="math inline">\(V\)</span>.</p>
</blockquote>
<p>Al definir la norma vectorial a partir de un producto escalar, además, tenemos la siguiente propiedad que será de gran interés en la <a href="espacios-euclídeos.html#ortho">siguiente sección</a>:</p>
<blockquote>
<p>(Desigualdad de Cauchy-Schwarz) Si <span class="math inline">\(\|\cdot\|\)</span> es una norma derivada del producto escalar <span class="math inline">\(\langle\cdot,\cdot\rangle\)</span>, entonces
<span class="math display">\[|\langle u, v \rangle| \le \|u\|\cdot\|v\|\]</span>
para todo <span class="math inline">\(u,v\in V\)</span>.</p>
</blockquote>
<p>Un concepto implícitamente relacionado con el de norma vectorial es el de <em>distancia</em>. Una <strong>distancia</strong> (también llamada <em>métrica</em>) es un operador <span class="math inline">\(d:V\times V\to R\)</span> que verifica las siguientes propiedades:</p>
<ul>
<li><span class="math inline">\(d(u, v) = 0\)</span> si, y solo si, <span class="math inline">\(u = v\)</span>.</li>
<li>Es simétrica: <span class="math inline">\(d(u, v) = d(v, u)\)</span>.</li>
<li>Cumple la desigualdad triangular: <span class="math inline">\(d(u, v) \le d(u, w) + d(w, v)\)</span>.</li>
</ul>
<p>Además, de aquí se deduce que <span class="math inline">\(d(u, v) \ge 0\)</span> para todo <span class="math inline">\(u,v\in V\)</span>.</p>
<p>Podemos deducir una distancia a partir de una norma, para así completar las relaciones existentes entre los conceptos aquí explicados:</p>
<blockquote>
<p>Si <span class="math inline">\(\|\cdot\|\)</span> es una norma sobre un espacio vectorial <span class="math inline">\(V\)</span>, entonces la aplicación <span class="math inline">\(d:V\times V\to \mathbb{R}\)</span> definida por
<span class="math display">\[d(u, v) = \|u-v\|\]</span>
para todo <span class="math inline">\(u,v\in V\)</span> es una <em>distancia</em>.</p>
</blockquote>
<p><strong>Nota</strong>: Existen muchas más normas de las que se deducen a partir de un producto escalar, al igual que más <em>distancias</em>.</p>
<hr />
<p><strong>Ejemplo</strong></p>
<p>Podemos deducir la expresión de la norma (a veces llamada <em>módulo</em>) de un vector <span class="math inline">\(v\in\mathbb{R}^n\)</span>.</p>
<p>Si <span class="math inline">\(v=\left(\begin{array}{c}v_1\\ v_2\\\vdots\\ v_n\end{array}\right)\)</span>, entonces
<span class="math display">\[\|v\| = \sqrt{v\cdot v} = \sqrt{v_1^2+v_2^2+\ldots+v_n^2}\]</span></p>
<p>Y así, además, deducimos la expresión para la distancia euclídea usual en <span class="math inline">\(\mathbb{R}^n\)</span>:
<span class="math display">\[d(u,v) = \|u - v\| = \sqrt{(u_1-v_1)^2+\ldots+(u_n-v_n)^2}\]</span></p>
<p>Como ejemplo, podemos calcular la norma del vector
<span class="math display">\[v = \left(\begin{array}{c} -2\\ 1\\ 1\\ 1 \end{array}\right) \]</span><span class="math display">\[\|v\| = \sqrt{(-2)^2+1^2+1^2+1^2} = \sqrt{7}\]</span></p>
<hr />
</div>
<div id="ortho" class="section level2" number="5.2">
<h2 number="5.2"><span class="header-section-number">5.2</span> Qué significa el concepto de ortogonalidad</h2>
<p>Si partimos de la <em>desigualdad de Cauchy-Schwarz</em> que <a href="espacios-euclídeos.html#norm">hemos visto antes</a>, podemos llegar a que
<span class="math display">\[-1 \le \frac{\langle u, v\rangle}{\|u\|\cdot\|v\|} \le 1\]</span>
para todo <span class="math inline">\(u,v\in V\)</span>.</p>
<p>Por otro lado, la función coseno restringida a <span class="math inline">\([0, \pi]\)</span>, es decir, <span class="math inline">\(\cos:[0,\pi]\to[-1,1]\)</span>, es biyectiva. Eso quiere decir que existe un único <span class="math inline">\(\theta\in[0, \pi]\)</span> tal que <span class="math inline">\(\cos\theta = \frac{\langle u, v\rangle}{\|u\|\cdot\|v\|}\)</span>.</p>
<p>Llamamos entonces <strong>ángulo entre los vectores <span class="math inline">\(u,v\in V\)</span></strong> al único <span class="math inline">\(\theta\in[0,\pi]\)</span> tal que <span class="math inline">\(\cos\theta = \frac{\langle u, v\rangle}{\|u\|\cdot\|v\|}\)</span>.</p>
<p>Diremos que dos vectores <span class="math inline">\(u\)</span> y <span class="math inline">\(v\)</span> de <span class="math inline">\(V\)</span> son <strong>ortogonales</strong> (o <strong>perpendiculares</strong>) si el ángulo que forman es <span class="math inline">\(\frac{\pi}{2}\)</span>, es decir, si <span class="math inline">\(\langle u, v \rangle = 0\)</span>.</p>
<p>La noción de <em>ortogonalidad</em> en el espacio euclídeo se corresponde con la perpendicularidad de vectores que todos tenemos de forma intuitiva. Lo podemos extender también a ortogonalidad con respecto a un espacio vectorial: Un vector <span class="math inline">\(v\in V\)</span> es <strong>ortogonal al subespacio <span class="math inline">\(U\)</span></strong> de <span class="math inline">\(V\)</span> si, y sólo si, es ortogonal a todos y cada uno de los vectores de <span class="math inline">\(U\)</span>, es decir, <span class="math inline">\(\langle v, u \rangle = 0\)</span> para todo <span class="math inline">\(u\in U\)</span>.</p>
<blockquote>
<p>Sea <span class="math inline">\(U\)</span> un subespacio de <span class="math inline">\(V\)</span>, y sea <span class="math inline">\(\mathcal{B} = \{u_1,\ldots,u_k\}\)</span> una base de <span class="math inline">\(U\)</span>. Un vector <span class="math inline">\(v\in V\)</span> es ortogonal a <span class="math inline">\(U\)</span> si, y solo si, es ortogonal a cada <span class="math inline">\(u_i\)</span>: <span class="math inline">\(\langle v, u_i \rangle = 0\)</span> para todo <span class="math inline">\(i=1,\ldots,k\)</span>.</p>
</blockquote>
<p>Un <strong>sistema ortogonal</strong> es un conjunto de vectores <span class="math inline">\(\{v_1,\ldots,v_m\}\subset V\)</span> donde los <span class="math inline">\(v_i\)</span> son ortogonales dos a dos, es decir, <span class="math inline">\(\langle v_i, v_j \rangle = 0\)</span> para todo <span class="math inline">\(i\ne j\)</span>.</p>
<p><strong>Algunas propiedades y caracterizaciones de los vectores y sistemas ortogonales</strong></p>
<blockquote>
<ul>
<li>Dos vectores <span class="math inline">\(u\)</span> y <span class="math inline">\(w\)</span> son ortogonales si, y solo si, <span class="math inline">\(\|u+w\|^2 = \|u\|^2 + \|v\|^2\)</span> (generalización del Teorema de Pitágoras).</li>
<li>Si un sistema de vectores es ortogonal, entonces es linealmente independiente. Por tanto, en un espacio <span class="math inline">\(V\)</span> de dimensión finita <span class="math inline">\(n\)</span>, cualquier conjunto de <span class="math inline">\(n\)</span> vectores ortogonales entre sí es una base.</li>
</ul>
</blockquote>
<p>Este último resultado es interesante, pues nos constata que cualquier sistema ortogonal con tantos vectores como la dimensión del espacio vectorial es una base.</p>
<hr />
<p><strong>Ejemplo</strong></p>
<p>Consideremos el espacio <span class="math inline">\(U\)</span> dado por:
<span class="math display">\[U = \left\{\left(\begin{array}{c} x\\ y\\ z\\ t \end{array}\right) \in\mathbb{R}^{4}:\begin{array}{ccr} -x+ 4y+ z &amp; = &amp; 0\\ y+ t &amp; = &amp; 0\\ \end{array}\right\}\]</span>
y los vectores
<span class="math display">\[v = \left(\begin{array}{c} 1\\ -2\\ -1\\ 2 \end{array}\right) \quad\quad w = \left(\begin{array}{c} -1\\ 2\\ -1\\ -1 \end{array}\right) \]</span></p>
<p>Calculemos el ángulo entre <span class="math inline">\(v\)</span> y <span class="math inline">\(w\)</span>:
<span class="math display">\[\theta = \arccos \frac{v\cdot w}{\|v\|\cdot\|w\|}\]</span><span class="math display">\[v\cdot w = 1\cdot(-1)+(-2)\cdot2+(-1)\cdot(-1)+2\cdot(-1) = -6\]</span><span class="math display">\[\|v\| = \sqrt{1^2+(-2)^2+(-1)^2+2^2} = \sqrt{10}\]</span><span class="math display">\[\|w\| = \sqrt{(-1)^2+2^2+(-1)^2+(-1)^2} = \sqrt{7}\]</span></p>
<p>Luego
<span class="math display">\[\theta = \arccos \frac{-6}{\sqrt{10}\sqrt{7}} = \arccos \frac{-3\cdot\sqrt{70}}{35}\]</span></p>
<p>Vamos a comprobar ahora que <span class="math inline">\(v\)</span> es ortogonal al subespacio <span class="math inline">\(U\)</span>. Para ello, a partir de las ecuaciones cartesianas de <span class="math inline">\(U\)</span>, vamos a <a href="ev.html#base">hallar una base</a> suya, resolviendo el sistema por Gauss-Jordan y pasando por las ecuaciones paramétricas:
<span class="math display">\[\left( \begin{array}{cccc@{}} -1 &amp; 4 &amp; 1 &amp; 0\\ 0 &amp; 1 &amp; 0 &amp; 1 \end{array} \right) \sim\left( \begin{array}{cccc@{}} 1 &amp; 0 &amp; -1 &amp; 4\\ 0 &amp; 1 &amp; 0 &amp; 1 \end{array} \right) \Rightarrow\left(\begin{array}{c} x\\ y\\ z\\ t \end{array}\right)  = \alpha\left(\begin{array}{c} 1\\ 0\\ 1\\ 0 \end{array}\right) {}+\beta\left(\begin{array}{c} -4\\ -1\\ 0\\ 1 \end{array}\right) {}\]</span></p>
<p>De aquí que la base de <span class="math inline">\(U\)</span> sea:
<span class="math display">\[\mathcal{B}_U = \left\{u_i\right\} = \left\{\left( \begin{array}{c@{}} 1\\ 0\\ 1\\ 0 \end{array} \right) , \left( \begin{array}{c@{}} -4\\ -1\\ 0\\ 1 \end{array} \right) \right\}\]</span></p>
<p>Como hemos visto antes, para comprobar que <span class="math inline">\(v\)</span> es ortogonal a <span class="math inline">\(U\)</span>, nos basta con comprobar que lo es a cada vector de <span class="math inline">\(\mathcal{B}_U\)</span>, hallando su producto escalar:
<span class="math display">\[\langle v, u_1 \rangle = \langle \left(\begin{array}{c} 1\\ -2\\ -1\\ 2 \end{array}\right) , \left(\begin{array}{c} 1\\ 0\\ 1\\ 0 \end{array}\right)  \rangle = 1\cdot1+(-2)\cdot0+(-1)\cdot1+2\cdot0 = 0\]</span><span class="math display">\[\langle v, u_2 \rangle = \langle \left(\begin{array}{c} 1\\ -2\\ -1\\ 2 \end{array}\right) , \left(\begin{array}{c} -4\\ -1\\ 0\\ 1 \end{array}\right)  \rangle = 1\cdot(-4)+(-2)\cdot(-1)+(-1)\cdot0+2\cdot1 = 0\]</span></p>
<p>Consideremos ahora el siguiente sistema de vectores:
<span class="math display">\[S = \{s_i\} = \left\{\left( \begin{array}{c@{}} 1\\ 1\\ 1\\ 0 \end{array} \right) , \left( \begin{array}{c@{}} -1\\ 2\\ -1\\ 0 \end{array} \right) , \left( \begin{array}{c@{}} 1\\ 0\\ -1\\ 2 \end{array} \right) , \left( \begin{array}{c@{}} -1\\ 0\\ 1\\ 1 \end{array} \right) \right\}\]</span></p>
<p>Podemos comprobar fácilmente que es un sistema ortogonal, hallando los productos escalares de los vectores de <span class="math inline">\(S\)</span> dos a dos:
<span class="math display">\[\langle s_1, s_2 \rangle = \langle \left(\begin{array}{c} 1\\ 1\\ 1\\ 0 \end{array}\right) , \left(\begin{array}{c} -1\\ 2\\ -1\\ 0 \end{array}\right)  \rangle = 1\cdot(-1)+1\cdot2+1\cdot(-1)+0\cdot0 = 0\]</span><span class="math display">\[\langle s_1, s_3 \rangle = \langle \left(\begin{array}{c} 1\\ 1\\ 1\\ 0 \end{array}\right) , \left(\begin{array}{c} 1\\ 0\\ -1\\ 2 \end{array}\right)  \rangle = 1\cdot1+1\cdot0+1\cdot(-1)+0\cdot2 = 0\]</span><span class="math display">\[\langle s_1, s_4 \rangle = \langle \left(\begin{array}{c} 1\\ 1\\ 1\\ 0 \end{array}\right) , \left(\begin{array}{c} -1\\ 0\\ 1\\ 1 \end{array}\right)  \rangle = 1\cdot(-1)+1\cdot0+1\cdot1+0\cdot1 = 0\]</span><span class="math display">\[\langle s_2, s_3 \rangle = \langle \left(\begin{array}{c} -1\\ 2\\ -1\\ 0 \end{array}\right) , \left(\begin{array}{c} 1\\ 0\\ -1\\ 2 \end{array}\right)  \rangle = (-1)\cdot1+2\cdot0+(-1)\cdot(-1)+0\cdot2 = 0\]</span><span class="math display">\[\langle s_2, s_4 \rangle = \langle \left(\begin{array}{c} -1\\ 2\\ -1\\ 0 \end{array}\right) , \left(\begin{array}{c} -1\\ 0\\ 1\\ 1 \end{array}\right)  \rangle = (-1)\cdot(-1)+2\cdot0+(-1)\cdot1+0\cdot1 = 0\]</span><span class="math display">\[\langle s_3, s_4 \rangle = \langle \left(\begin{array}{c} 1\\ 0\\ -1\\ 2 \end{array}\right) , \left(\begin{array}{c} -1\\ 0\\ 1\\ 1 \end{array}\right)  \rangle = 1\cdot(-1)+0\cdot0+(-1)\cdot1+2\cdot1 = 0\]</span></p>
<p>Tenemos, por tanto, un sistema de 4 vectores ortogonales en <span class="math inline">\(\mathbb{R}^{4}\)</span>, y, como hemos comentado antes, son linealmente independientes, luego forman una base del espacio vectorial.</p>
</div>
<div id="compl-ortho" class="section level2" number="5.3">
<h2 number="5.3"><span class="header-section-number">5.3</span> Qué es el complemento ortogonal de un subespacio</h2>
<p>Consideremos un espacio vectorial <span class="math inline">\(V\)</span> con producto escalar <span class="math inline">\(\langle \cdot,\cdot \rangle\)</span>, y sea <span class="math inline">\(U\)</span> un subespacio de <span class="math inline">\(V\)</span>.</p>
<p>Llamamos <strong>complemento ortogonal de <span class="math inline">\(U\)</span></strong> al conjunto de vectores que son ortogonales a todos los de <span class="math inline">\(U\)</span>:
<span class="math display">\[U^{\perp} = \{v\in V: \langle v, u \rangle = 0\,\,\text{para todo }u\in U\}\]</span></p>
<p>Tenemos las siguientes propiedades del complemento ortogonal de un subespacio:</p>
<blockquote>
<ul>
<li><span class="math inline">\(U^{\perp}\)</span> es un subespacio vectorial de <span class="math inline">\(V\)</span>.</li>
<li><span class="math inline">\(U\cap U^{\perp} = \{0\}\)</span>.</li>
<li>Si <span class="math inline">\(V\)</span> es de dimensión finita, <span class="math inline">\(\mathrm{dim}(U) + \mathrm{dim}(U^{\perp}) = \mathrm{dim}(V)\)</span>.</li>
</ul>
</blockquote>
<p>Como consecuencia, este resultado nos dice que <strong><span class="math inline">\(V\)</span> se puede descomponer como la suma directa de <span class="math inline">\(U\)</span> y de su complemento ortogonal</strong>: <span class="math inline">\(U\oplus U^{\perp} = V\)</span>.</p>
<p><strong>¿Cómo calculamos el complemento ortogonal de un subespacio?</strong></p>
<p>Hemos de hallar los vectores que son ortogonales a un subespacio <span class="math inline">\(U\)</span>. Como hemos <a href="espacios-euclídeos.html#ortho">visto antes</a>, un vector <span class="math inline">\(v\)</span> es ortogonal a <span class="math inline">\(U\)</span> si, y solo si, es ortogonal a todos los vectores de una base de <span class="math inline">\(U\)</span>.</p>
<p>Así pues, partimos de que tenemos una base <span class="math inline">\(\mathcal{B} = \{u_1,\ldots,u_m\}\)</span> de <span class="math inline">\(U\)</span> y tomemos un vector genérico <span class="math inline">\(v\in V\)</span>. Para que <span class="math inline">\(v\in U^{\perp}\)</span>, debe cumplirse que <span class="math inline">\(\langle v, u_i\rangle = 0\)</span> para todo <span class="math inline">\(i=1,\ldots,m\)</span>.</p>
<p>Cada una de las restricciones <span class="math inline">\(\langle v, u_i\rangle = 0\)</span> nos proporciona una ecuación lineal que debe verificar un vector para poder pertenecer a <span class="math inline">\(U^{\perp}\)</span>.</p>
<p>Tomamos, por tanto, todas las ecuaciones lineales que se deducen de las restricciones anteriores: ese sistema de ecuaciones nos representa las ecuaciones cartesianas del espacio <span class="math inline">\(U^{\perp}\)</span>.</p>
<p>En el caso concreto de un espacio <span class="math inline">\(V=\mathbb{R}^n\)</span> con el <em>producto escalar euclídeo</em>, podemos ver qué aspecto tienen las ecuaciones del tipo <span class="math inline">\(\langle v, u_i \rangle = 0\)</span>. Supongamos que los vectores <span class="math inline">\(v\)</span> y <span class="math inline">\(u_i\)</span> tienen por coordenadas, en la base canónica, las siguientes:
<span class="math display">\[v = \left(
\begin{array}{c}
x_1\\ x_2\\ \vdots \\ x_n\\
\end{array}\right), \quad 
u_i = \left(
\begin{array}{c}
\alpha_{i,1}\\ \alpha_{i,2}\\ \vdots \\ \alpha_{i,n}\\
\end{array}\right)\]</span></p>
<p>Entonces
<span class="math display">\[
\langle v, u_i \rangle = 0 \Leftrightarrow 
\langle \left(
\begin{array}{c}
x_1\\ x_2\\ \vdots \\ x_n\\
\end{array}\right) , 
\left(
\begin{array}{c}
\alpha_{i,1}\\ \alpha_{i,2}\\ \vdots \\ \alpha_{i,n}\\
\end{array}\right) \rangle = 0 \Leftrightarrow \alpha_{i,1}x_1+\alpha_{i,2}x_2+\ldots+\alpha_{i,n}x_n = 0
\]</span></p>
<p>Si nos fijamos, nos queda una ecuación lineal cuyas incógnitas son las coordenadas canónicas de <span class="math inline">\(v\)</span> y cuyos coeficientes son las coordenadas de <span class="math inline">\(u_i\)</span>. Si repetimos el proceso para todo <span class="math inline">\(i=1,\ldots,m\)</span>, tenemos el siguiente sistema de ecuaciones:
<span class="math display">\[Av = 0\quad\text{donde}\quad A = \left(
\begin{array}{cccc}
\alpha_{1,1} &amp; \alpha_{1,2} &amp; \ldots &amp; \alpha_{1,n} \\
\alpha_{2,1} &amp; \alpha_{2,2} &amp; \ldots &amp; \alpha_{2,n} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\alpha_{m,1} &amp; \alpha_{m,2} &amp; \ldots &amp; \alpha_{m,n} \\
\end{array}
\right)\]</span></p>
<p>Es decir, las <em>ecuaciones cartesianas</em> de <span class="math inline">\(U^{\perp}\)</span> son las que tienen por matriz de coeficientes a las coordenadas de los vectores de la base de <span class="math inline">\(U\)</span> puestos por filas. De hecho, si llamamos <span class="math inline">\(B\)</span> a la matriz que resulta de poner por columnas los vectores de <span class="math inline">\(\mathcal{B}\)</span>, entonces <span class="math inline">\(A = B^{\mathrm{t}}\)</span>.</p>
<p>A partir de esas ecuaciones cartesianas, ya podríamos <a href="ev.html#base">encontrar una base</a> del subespacio <span class="math inline">\(U^{\perp}\)</span>.</p>
<hr />
<p><strong>Ejemplo</strong></p>
<p>Consideremos el espacio <span class="math inline">\(U\)</span> generado por la base siguiente:
<span class="math display">\[\mathcal{B} = \{u_i\} = \left\{\left( \begin{array}{c@{}} -2\\ 0\\ -2\\ 2 \end{array} \right) , \left( \begin{array}{c@{}} -1\\ -1\\ -2\\ 2 \end{array} \right) \right\}\]</span></p>
<p>Para hallar su complemento ortogonal, suponemos un vector genérico
<span class="math display">\[v = \left(\begin{array}{c} x\\ y\\ z\\ t \end{array}\right) \in \mathbb{R}^{4}\]</span>
y hacemos su producto escalar por todos los vectores de <span class="math inline">\(\mathcal{B}\)</span>, imponiendo que valga 0:
<span class="math display">\[\langle v, u_1 \rangle = 0\Leftrightarrow\langle \left(\begin{array}{c} x\\ y\\ z\\ t \end{array}\right) , \left(\begin{array}{c} -2\\ 0\\ -2\\ 2 \end{array}\right)  = 0\Leftrightarrow\ \begin{array}{ccr} -2x-2z+ 2t &amp; = &amp; 0\\ \end{array}\]</span><span class="math display">\[\langle v, u_2 \rangle = 0\Leftrightarrow\langle \left(\begin{array}{c} x\\ y\\ z\\ t \end{array}\right) , \left(\begin{array}{c} -1\\ -1\\ -2\\ 2 \end{array}\right)  = 0\Leftrightarrow\ \begin{array}{ccr} -x-y-2z+ 2t &amp; = &amp; 0\\ \end{array}\]</span></p>
<p>Hemos llegado, por tanto, al siguiente sistema de ecuaciones que representan las ecuaciones cartesianas de <span class="math inline">\(U^{\perp}\)</span>:
<span class="math display">\[\begin{array}{rrrrcr} -2x &amp;  &amp; -2z &amp; + 2t &amp; = &amp; 0\\ -x &amp; -y &amp; -2z &amp; + 2t &amp; = &amp; 0\\ \end{array}\]</span>
Nos podemos dar cuenta de que la matriz del sistema es la que resulta de poner los vectores de la base <span class="math inline">\(\mathcal{B}\)</span> <em>por filas</em>.</p>
<p>Como siempre, podemos resolver el sistema por Gauss-Jordan para <a href="ev.html#param2cartesian">deducir la forma paramétrica</a> de la solución, y, por tanto, un <a href="#sisgen">sistema generador</a> de <span class="math inline">\(U^{\perp}\)</span>:
<span class="math display">\[\left( \begin{array}{cccc@{}} -2 &amp; 0 &amp; -2 &amp; 2\\ -1 &amp; -1 &amp; -2 &amp; 2 \end{array} \right) \sim\left( \begin{array}{cccc@{}} 1 &amp; 0 &amp; 1 &amp; -1\\ 0 &amp; 1 &amp; 1 &amp; -1 \end{array} \right) \Rightarrow\left(\begin{array}{c} x\\ y\\ z\\ t \end{array}\right)  = \alpha\left(\begin{array}{c} -1\\ -1\\ 1\\ 0 \end{array}\right) {}+\beta\left(\begin{array}{c} 1\\ 1\\ 0\\ 1 \end{array}\right) {}\]</span></p>
<p>De aquí que una base del complemento ortogonal <span class="math inline">\(U^{\perp}\)</span> sea:
<span class="math display">\[\mathcal{B}&#39; = \left\{\left( \begin{array}{c@{}} -1\\ -1\\ 1\\ 0 \end{array} \right) , \left( \begin{array}{c@{}} 1\\ 1\\ 0\\ 1 \end{array} \right) \right\}\]</span></p>
<p>Podemos comprobar fácilmente que los vectores de <span class="math inline">\(\mathcal{B}&#39;\)</span> son ortogonales a los de <span class="math inline">\(\mathcal{B}\)</span>.</p>
<hr />
</div>
<div id="proyec" class="section level2" number="5.4">
<h2 number="5.4"><span class="header-section-number">5.4</span> Cómo calculamos la proyección de un vector sobre un subespacio</h2>
<p>Consideremos un espacio euclídeo <span class="math inline">\(\left(V, \langle\cdot,\cdot\rangle\right)\)</span>. Consideremos un subespacio <span class="math inline">\(U\)</span>, del que conocemos una <a href="espacios-euclídeos.html#ortho">base <em>ortogonal</em></a> <span class="math inline">\(\mathcal{B}_U = \{u_1,\ldots,u_m\}\)</span>. Definimos la <strong>proyección <em>ortogonal</em> de un vector <span class="math inline">\(v\)</span> sobre el subespacio <span class="math inline">\(U\)</span></strong>, como:
<span class="math display">\[\mathrm{proy}_U(v) = \frac{\langle v, u_1\rangle}{\langle u_1, u_1 \rangle}u_1 + \frac{\langle v, u_2\rangle}{\langle u_2, u_2 \rangle}u_2 + \ldots + \frac{\langle v, u_m\rangle}{\langle u_m, u_m \rangle}u_m\]</span></p>
<p>Es decir, la proyección <span class="math inline">\(\mathrm{proy}_U(v)\)</span> es un vector del subespacio <span class="math inline">\(U\)</span>, ya que es combinación lineal de los elementos de su base, y además esta combinación lineal tiene como coeficientes el producto escalar de <span class="math inline">\(v\)</span> por cada elemento de la base, dividido por la norma de <span class="math inline">\(u_i\)</span> al cuadrado (<a href="espacios-euclídeos.html#norm">recordemos que <span class="math inline">\(\|x\| = \sqrt{\langle x,x \rangle}\)</span></a>).</p>
<p>Evidentemente, si los elementos de la base de <span class="math inline">\(U\)</span> tienen norma 1, el denominador desaparece.</p>
<p>La proyección de <span class="math inline">\(v\)</span> sobre el subespacio <span class="math inline">\(U\)</span> tiene la propiedad siguiente:</p>
<blockquote>
<p>Si <span class="math inline">\(u\)</span> es un vector del subespacio <span class="math inline">\(U\)</span>, y <span class="math inline">\(v\in V\)</span>, entonces <span class="math inline">\(d(u, v) \ge d(\mathrm{proy}_U(v), v)\)</span>, y la única forma para que se dé la igualdad es que <span class="math inline">\(u = \mathrm{proy}_U(v)\)</span>.</p>
</blockquote>
<p>Esto significa que la proyección ortogonal de <span class="math inline">\(v\)</span> sobre <span class="math inline">\(U\)</span> es el vector de <span class="math inline">\(U\)</span> más cercano (según la distancia <span class="math inline">\(d\)</span>) a <span class="math inline">\(v\)</span>.</p>
<p>Como caso particular, podríamos definir la <strong>proyección ortogonal de un vector <span class="math inline">\(v\)</span> sobre otro vector <span class="math inline">\(u\)</span></strong> como
<span class="math display">\[\mathrm{proy}_u(v) = \frac{\langle v, u \rangle}{\langle u, u\rangle}u\]</span>
(realmente es la proyección del vector <span class="math inline">\(v\)</span> sobre el <a href="#sisgen">subespacio generado</a> por el vector <span class="math inline">\(u\)</span>).</p>
<p>Podemos entonces concluir que, si la base ortogonal de <span class="math inline">\(U\)</span> es <span class="math inline">\(\mathcal{B}_U = \{u_1,\ldots,u_m\}\)</span>, entonces
<span class="math display">\[\mathrm{proy}_U(v) = \mathrm{proy}_{u_1}(v)+\ldots+\mathrm{proy}_{u_m}(v)\]</span></p>
<p>A partir del hecho de que la base de <span class="math inline">\(U\)</span> es <em>ortogonal</em>, podemos deducir que:</p>
<blockquote>
<p>Si <span class="math inline">\(U\)</span> es un subespacio de <span class="math inline">\(V\)</span>, <span class="math inline">\(v\in V\)</span>, y una base ortogonal de <span class="math inline">\(U\)</span> es <span class="math inline">\(\mathcal{B}_U = \{u_1,\ldots,u_m\}\)</span>, entonces el vector <span class="math inline">\(v - \mathrm{proy}_U(v)\)</span> es ortogonal a <span class="math inline">\(U\)</span>, es decir, <span class="math inline">\(v - \mathrm{proy}_U(v) \in U^{\perp}\)</span> está en el <a href="espacios-euclídeos.html#compl-ortho">complemento ortogonal</a> de <span class="math inline">\(U\)</span>.</p>
</blockquote>
<p>Esto, junto con que <span class="math inline">\(\mathrm{proy}_U(v)\in U\)</span>, nos justifican el siguiente resultado, llamado <strong>teorema de la descomposición ortogonal</strong>:</p>
<blockquote>
<p>En un espacio euclídeo <span class="math inline">\((V, \langle\cdot,\cdot\rangle)\)</span>, dado un subespacio <span class="math inline">\(U\)</span>, y <span class="math inline">\(v\in V\)</span>, existe una única descomposición de <span class="math inline">\(v\)</span> como suma de dos vectores ortogonales, <span class="math inline">\(v = v_1 + v_2\)</span>, tales que <span class="math inline">\(v_1\in U\)</span> y <span class="math inline">\(v_2\in U^{\perp}\)</span>. Concretamente, <span class="math inline">\(v_1 = \mathrm{proy}_U(v)\)</span> y <span class="math inline">\(v_2 = v - v_1 = \mathrm{proy}_{U^{\perp}}(v)\)</span>.</p>
</blockquote>
<p>Podemos siempre descomponer un vector de <span class="math inline">\(V\)</span> como suma de dos vectores, uno de <span class="math inline">\(U\)</span> y otro de <span class="math inline">\(U^{\perp}\)</span>, que coinciden con las proyecciones sobre ambos subespacios.</p>
<hr />
<p><strong>Ejemplo</strong></p>
<p>Consideremos el subespacio <span class="math inline">\(U\)</span> cuya base es
<span class="math display">\[\mathcal{B} = \{u_i\} = \left\{\left( \begin{array}{c@{}} -1\\ 1\\ -1\\ -1 \end{array} \right) , \left( \begin{array}{c@{}} -3\\ -5\\ 1\\ -3 \end{array} \right) \right\}\]</span></p>
<p>Notemos que <span class="math inline">\(\mathcal{B}\)</span> es una base <em>ortogonal</em>.</p>
<p>Consideremos el vector
<span class="math display">\[v = \left( \begin{array}{c@{}} -1\\ 1\\ -2\\ 0 \end{array} \right) \]</span></p>
<p>Buscamos la <em>descomposición ortogonal</em> de <span class="math inline">\(v\)</span> con respecto al subespacio <span class="math inline">\(U\)</span>. Sabemos que podemos escribir <span class="math inline">\(v = v_1 + v_2\)</span>, donde <span class="math inline">\(v_1 = \mathrm{proy}_U(v)\)</span> y <span class="math inline">\(v_2 = v - v_1 \in U^{\perp}\)</span>.
<span class="math display">\[v_1 = \mathrm{proy}_U(v) = \mathrm{proy}_{u_1}(v)+\mathrm{proy}_{u_2}(v) = \frac{\langle v, u_1\rangle}{\langle u_1, u_1 \rangle} u_1+\frac{\langle v, u_2\rangle}{\langle u_2, u_2 \rangle} u_2\]</span></p>
<p>Si calculamos esas cantidades
<span class="math display">\[\langle v, u_1 \rangle = \langle \left(\begin{array}{c} -1\\ 1\\ -2\\ 0 \end{array}\right) , \left(\begin{array}{c} -1\\ 1\\ -1\\ -1 \end{array}\right)  \rangle = (-1)\cdot(-1)+1\cdot1+(-2)\cdot(-1)+0\cdot(-1) = 4\]</span><span class="math display">\[\langle v, u_2 \rangle = \langle \left(\begin{array}{c} -1\\ 1\\ -2\\ 0 \end{array}\right) , \left(\begin{array}{c} -3\\ -5\\ 1\\ -3 \end{array}\right)  \rangle = (-1)\cdot(-3)+1\cdot(-5)+(-2)\cdot1+0\cdot(-3) = -4\]</span><span class="math display">\[\langle u_1, u_1 \rangle = \langle \left(\begin{array}{c} -1\\ 1\\ -1\\ -1 \end{array}\right) , \left(\begin{array}{c} -1\\ 1\\ -1\\ -1 \end{array}\right)  \rangle = (-1)^2+1^2+(-1)^2+(-1)^2 = 4\]</span><span class="math display">\[\langle u_2, u_2 \rangle = \langle \left(\begin{array}{c} -3\\ -5\\ 1\\ -3 \end{array}\right) , \left(\begin{array}{c} -3\\ -5\\ 1\\ -3 \end{array}\right)  \rangle = (-3)^2+(-5)^2+1^2+(-3)^2 = 44\]</span>
podemos sustituirlas en la expresión de más arriba y llegamos a
<span class="math display">\[v_1 = 1\cdot\left(\begin{array}{c} -1\\ 1\\ -1\\ -1 \end{array}\right) +(- \frac{1}{11})\cdot\left(\begin{array}{c} -3\\ -5\\ 1\\ -3 \end{array}\right)  = \left( \begin{array}{c@{}} - \frac{8}{11}\\ \frac{16}{11}\\ - \frac{12}{11}\\ - \frac{8}{11} \end{array} \right) \]</span></p>
<p>Por tanto,
<span class="math display">\[v_2 = \left( \begin{array}{c@{}} -1\\ 1\\ -2\\ 0 \end{array} \right)  - \left( \begin{array}{c@{}} - \frac{8}{11}\\ \frac{16}{11}\\ - \frac{12}{11}\\ - \frac{8}{11} \end{array} \right)  = \left( \begin{array}{c@{}} - \frac{3}{11}\\ - \frac{5}{11}\\ - \frac{10}{11}\\ \frac{8}{11} \end{array} \right) \]</span></p>
<p>Por lo comentado anteriormente, sabemos que <span class="math inline">\(v_2 = \mathrm{proy}_{U^{\perp}}(v)\in U^{\perp}\)</span>, lo cual se podría comprobar haciendo el producto escalar <span class="math inline">\(\langle v_2, u_i \rangle\)</span> y viendo que su valor es 0 para todo <span class="math inline">\(i\)</span>.</p>
<hr />
</div>
<div id="ortho-basis" class="section level2" number="5.5">
<h2 number="5.5"><span class="header-section-number">5.5</span> Qué es y qué utilidad tiene una base ortonormal</h2>
<p>Un vector <span class="math inline">\(v\in V\)</span> se dice <strong>unitario</strong> si <span class="math inline">\(\|v\| = 1\)</span>. Es fácil crear vectores unitarios: dado <span class="math inline">\(u\in V\)</span>, si definimos <span class="math inline">\(v = \frac{1}{\|u\|}u\)</span>, este vector tiene norma 1. A este proceso se le llama <em>normalizar</em>.</p>
<p>Un sistema de vectores <span class="math inline">\(\{v_1,\ldots,v_k\}\)</span> se llama <strong>sistema ortonormal</strong> si es un <a href="espacios-euclídeos.html#ortho">sistema ortogonal</a> y cada <span class="math inline">\(v_i\)</span> es un vector unitario (<span class="math inline">\(i=1,\ldots, k\)</span>).</p>
<p>En relación a lo comentado de las propiedades de los sistemas ortogonales, en nuestro caso podemos decir que un sistema ortonormal <span class="math inline">\(\{v_1,\ldots,v_n\}\)</span>, donde <span class="math inline">\(\mathrm{dim}(V) = n\)</span>, es una <strong>base ortonormal</strong>.</p>
<p>El interés de una base ortonormal es que es sencillo calcular las <a href="ev.html#coord">coordenadas</a> de cualquier vector con respecto a dicha base:</p>
<blockquote>
<p>Sea <span class="math inline">\(\mathcal{B} = \{v_1,\ldots,v_n\}\)</span> una base <em>ortonormal</em> del espacio vectorial <span class="math inline">\(V\)</span>. Entonces, para cada <span class="math inline">\(v\in V\)</span>, tenemos:
<span class="math display">\[v = \langle v, v_1 \rangle v_1 + \ldots \langle v, v_n \rangle v_n\]</span>
luego las coordenadas de <span class="math inline">\(v\)</span> en la base <span class="math inline">\(\mathcal{B}\)</span> las podemos calcular como:
<span class="math display">\[[v]_{\mathcal{B}} = \left(
\begin{array}{c}
\langle v, v_1 \rangle \\
\langle v, v_2 \rangle \\
\vdots \\
\langle v, v_n \rangle \\
\end{array}
\right)_{\mathcal{B}}\]</span></p>
</blockquote>
<hr />
<p><strong>Ejemplo</strong></p>
<p>Consideremos ahora el sistema de vectores ortogonales del <a href="espacios-euclídeos.html#ortho">ejemplo anterior</a>:
<span class="math display">\[S = \{s_i\} = \left\{\left( \begin{array}{c@{}} 1\\ 1\\ 1\\ 0 \end{array} \right) , \left( \begin{array}{c@{}} -1\\ 2\\ -1\\ 0 \end{array} \right) , \left( \begin{array}{c@{}} 1\\ 0\\ -1\\ 2 \end{array} \right) , \left( \begin{array}{c@{}} -1\\ 0\\ 1\\ 1 \end{array} \right) \right\}\]</span></p>
<p>A partir de <span class="math inline">\(S\)</span>, formemos un sistema ortonormal <span class="math inline">\(S&#39;\)</span>, donde cada vector de <span class="math inline">\(S&#39;\)</span> es un vector de <span class="math inline">\(S\)</span>, que se ha normalizado.
<span class="math display">\[S&#39; = \left\{\left(\begin{array}{c} \frac{\sqrt{3}}{3}\\ \frac{\sqrt{3}}{3}\\ \frac{\sqrt{3}}{3}\\ 0 \end{array}\right), \left(\begin{array}{c} \frac{-\sqrt{6}}{6}\\ \frac{\sqrt{6}}{3}\\ \frac{-\sqrt{6}}{6}\\ 0 \end{array}\right), \left(\begin{array}{c} \frac{\sqrt{6}}{6}\\ 0\\ \frac{-\sqrt{6}}{6}\\ \frac{\sqrt{6}}{3} \end{array}\right), \left(\begin{array}{c} \frac{-\sqrt{3}}{3}\\ 0\\ \frac{\sqrt{3}}{3}\\ \frac{\sqrt{3}}{3} \end{array}\right)\right\}\]</span></p>
<p><span class="math inline">\(S&#39;\)</span> forma una base <em>ortonormal</em> de <span class="math inline">\(\mathbb{R}^{4}\)</span>.
Si consideramos el vector
<span class="math display">\[v = \left( \begin{array}{c@{}} -1\\ 1\\ -2\\ 0 \end{array} \right) \]</span>
podemos hallar sus coordenadas en la base <span class="math inline">\(S&#39;\)</span>, ya que cada coordenada de <span class="math inline">\(v\)</span> será el producto escalar de <span class="math inline">\(v\)</span> por el correspondiente vector de <span class="math inline">\(S&#39;\)</span>:
<span class="math display">\[\langle v, s&#39;_1 \rangle = \langle \left(\begin{array}{c} -1\\ 1\\ -2\\ 0 \end{array}\right), \left(\begin{array}{c} \frac{\sqrt{3}}{3}\\ \frac{\sqrt{3}}{3}\\ \frac{\sqrt{3}}{3}\\ 0 \end{array}\right) \rangle = \frac{-2\cdot\sqrt{3}}{3}\]</span><span class="math display">\[\langle v, s&#39;_2 \rangle = \langle \left(\begin{array}{c} -1\\ 1\\ -2\\ 0 \end{array}\right), \left(\begin{array}{c} \frac{-\sqrt{6}}{6}\\ \frac{\sqrt{6}}{3}\\ \frac{-\sqrt{6}}{6}\\ 0 \end{array}\right) \rangle = \frac{5\cdot\sqrt{6}}{6}\]</span><span class="math display">\[\langle v, s&#39;_3 \rangle = \langle \left(\begin{array}{c} -1\\ 1\\ -2\\ 0 \end{array}\right), \left(\begin{array}{c} \frac{\sqrt{6}}{6}\\ 0\\ \frac{-\sqrt{6}}{6}\\ \frac{\sqrt{6}}{3} \end{array}\right) \rangle = \frac{\sqrt{6}}{6}\]</span><span class="math display">\[\langle v, s&#39;_4 \rangle = \langle \left(\begin{array}{c} -1\\ 1\\ -2\\ 0 \end{array}\right), \left(\begin{array}{c} \frac{-\sqrt{3}}{3}\\ 0\\ \frac{\sqrt{3}}{3}\\ \frac{\sqrt{3}}{3} \end{array}\right) \rangle = \frac{-\sqrt{3}}{3}\]</span></p>
<p>Entonces, podremos escribir:
<span class="math display">\[v = \left(\begin{array}{c} \frac{-2\cdot\sqrt{3}}{3}\\ \frac{5\cdot\sqrt{6}}{6}\\ \frac{\sqrt{6}}{6}\\ \frac{-\sqrt{3}}{3} \end{array}\right)_{S&#39;}\]</span></p>
<hr />
</div>
<div id="gram-schmidt" class="section level2" number="5.6">
<h2 number="5.6"><span class="header-section-number">5.6</span> Cómo construimos una base ortonormal</h2>
<p>En las secciones anteriores hemos usado bases ortogonales y ortonormales, pero cabe preguntarnos si la existencia de tales bases está asegurada. La respuesta nos la da el siguiente resultado:</p>
<blockquote>
<p>Sea <span class="math inline">\(V\)</span> un espacio vectorial euclídeo de <em>dimensión finita</em>. Entonces <span class="math inline">\(V\)</span> tiene una base ortonormal.</p>
</blockquote>
<p>La demostración de este resultado teórico realmente nos presenta un método constructivo que permite hallar una base ortonormal del espacio <span class="math inline">\(V\)</span> a partir de una base cualquiera.</p>
<p><strong>Método de Ortonormalización de Gram-Schmidt</strong></p>
<p>Consideremos una base <span class="math inline">\(\mathcal{B} = \{v_1,\ldots,v_n\}\)</span> en <span class="math inline">\(V\)</span>. Vamos a utilizar el método de Gram-Schmidt para construir una base ortonormal a partir de ella.</p>
<p>El proceso se divide en dos fases:</p>
<ul>
<li>En la primera fase, construiremos una base ortogonal <span class="math inline">\(\mathcal{B}&#39;\)</span>.</li>
<li>En un segundo paso, cada vector de <span class="math inline">\(\mathcal{B}&#39;\)</span> se normaliza, de forma que obtendremos una base ortonormal.</li>
</ul>
<p><em>Primera fase</em></p>
<p>El proceso del primer paso es incremental.</p>
<p>Llamamos <span class="math inline">\(u_1 = v_1\)</span>, el primer vector de la base <span class="math inline">\(\mathcal{B}\)</span>.</p>
<p>Ahora consideramos el segundo vector <span class="math inline">\(v_2\)</span>. Por un <a href="espacios-euclídeos.html#proyec">resultado teórico</a> sobre las proyecciones que vimos antes, si llamamos <span class="math inline">\(U_1 = \mathcal{L}(\{u_1\})\)</span>, entonces <span class="math inline">\(v_2 - \mathrm{proy}_{U_1}(v_2)\)</span> es un vector ortogonal a <span class="math inline">\(U_1\)</span>, en particular es ortogonal a <span class="math inline">\(u_1\)</span>.</p>
<p>Llamemos entonces <span class="math inline">\(u_2 = v_2 - \mathrm{proy}_{U_1}(v_2)\)</span>.
Entonces, el sistema <span class="math inline">\(\{u_1, u_2\}\)</span> es ortogonal.</p>
<p>Llamamos ahora <span class="math inline">\(U_2 = \mathcal{L}(\{u_1,u_2\})\)</span>. Entonces, por el mismo motivo que antes, si llamamos <span class="math inline">\(u_3 = v_3 - \mathrm{proy}_{U_2}(v_3)\)</span>, tenemos que <span class="math inline">\(u_3\)</span> es ortogonal a <span class="math inline">\(U_2\)</span>, luego <span class="math inline">\(\{u_1, u_2, u_3\}\)</span> es un sistema ortogonal.</p>
<p>De esta forma, sucesivamente, en el paso <span class="math inline">\(m\)</span>, vamos construyendo <span class="math inline">\(U_m = \mathcal{L}(\{u_1,\ldots,u_m\})\)</span> y consideramos <span class="math inline">\(u_{m+1} = v_{m+1} - \mathrm{proy}_{U_m}(v_{m+1})\)</span>, que es un vector ortogonal a <span class="math inline">\(U_m\)</span> y, por tanto, <span class="math inline">\(\{u_1,\ldots,u_{m+1}\}\)</span> es un sistema ortogonal.</p>
<p>Una vez se haya completado el proceso, se habrá construido el conjunto <span class="math inline">\(\mathcal{B}&#39; = \{u_1,\ldots,u_n\}\)</span>. Como estamos en un espacio <span class="math inline">\(V\)</span> de dimensión <span class="math inline">\(n\)</span>, y tenemos <span class="math inline">\(n\)</span> vectores ortogonales, luego <a href="espacios-euclídeos.html#ortho">linealmente independientes</a>, éstos forman una base. Luego <span class="math inline">\(\mathcal{B}&#39;\)</span> es una base ortogonal.</p>
<p><em>Segunda fase</em></p>
<p>La segunda fase es más sencilla, ya que implica únicamente normalizar cada vector de <span class="math inline">\(\mathcal{B}&#39;\)</span>.</p>
<p>De esta forma, la base ortonormal es la formada por
<span class="math display">\[\left\{\frac{u_1}{\|u_1\|}, \ldots, \frac{u_n}{\|u_n\|}\right\}\]</span></p>
<hr />
<p><strong>Ejemplo</strong></p>
<p>Consideremos la base <span class="math inline">\(\mathcal{B}\)</span> en <span class="math inline">\(\mathbb{R}^{4}\)</span> dada por
<span class="math display">\[\mathcal{B} = \{v_i\} = \left\{\left( \begin{array}{c@{}} -1\\ -1\\ -1\\ -1 \end{array} \right) , \left( \begin{array}{c@{}} 1\\ -1\\ 1\\ -1 \end{array} \right) , \left( \begin{array}{c@{}} -1\\ -1\\ 0\\ -1 \end{array} \right) , \left( \begin{array}{c@{}} -1\\ 1\\ 1\\ -1 \end{array} \right) \right\}\]</span></p>
<p>Vamos a usar el método de Gram-Schmidt para encontrar una base ortonormal, a partir de <span class="math inline">\(\mathcal{B}\)</span>.</p>
<p><em>Fase 1</em></p>
<p>Llamamos
<span class="math display">\[u_1 = v_1 = \left(\begin{array}{c} -1\\ -1\\ -1\\ -1 \end{array}\right) \]</span></p>
<p>A partir de este momento, procedemos de forma recursiva:</p>
<ul>
<li>Construimos:
<span class="math display">\[U_1 = \mathcal{L}(\{u_1\}) = \mathcal{L}(\left\{\left( \begin{array}{c@{}} -1\\ -1\\ -1\\ -1 \end{array} \right) \right\})\]</span>
Entonces
<span class="math display">\[\begin{array}{rcl}\mathrm{proy}_{U_1}(v_2) &amp; = &amp; \frac{\langle v_2, u_1 \rangle}{\langle u_1, u_1 \rangle} u_1 \\ &amp; = &amp; \frac{0}{4} \left( \begin{array}{c@{}} -1\\ -1\\ -1\\ -1 \end{array} \right)  \\ &amp; = &amp; \left( \begin{array}{c@{}} 0\\ 0\\ 0\\ 0 \end{array} \right) \\\end{array}\]</span>
Y llamamos
<span class="math display">\[u_2  = v_2 - \mathrm{proy}_{U_1}(v_2) = \left(\begin{array}{c} 1\\ -1\\ 1\\ -1 \end{array}\right)  - \left( \begin{array}{c@{}} 0\\ 0\\ 0\\ 0 \end{array} \right)  =  \left( \begin{array}{c@{}} 1\\ -1\\ 1\\ -1 \end{array} \right) \]</span></li>
<li>Construimos:
<span class="math display">\[U_2 = \mathcal{L}(\{u_1, u_2\}) = \mathcal{L}(\left\{\left( \begin{array}{c@{}} -1\\ -1\\ -1\\ -1 \end{array} \right) , \left( \begin{array}{c@{}} 1\\ -1\\ 1\\ -1 \end{array} \right) \right\})\]</span>
Entonces
<span class="math display">\[\begin{array}{rcl}\mathrm{proy}_{U_2}(v_3) &amp; = &amp; \frac{\langle v_3, u_1 \rangle}{\langle u_1, u_1 \rangle} u_1+\frac{\langle v_3, u_2 \rangle}{\langle u_2, u_2 \rangle} u_2 \\ &amp; = &amp; \frac{3}{4} \left( \begin{array}{c@{}} -1\\ -1\\ -1\\ -1 \end{array} \right) +\frac{1}{4} \left( \begin{array}{c@{}} 1\\ -1\\ 1\\ -1 \end{array} \right)  \\ &amp; = &amp; \left( \begin{array}{c@{}} - \frac{1}{2}\\ -1\\ - \frac{1}{2}\\ -1 \end{array} \right) \\\end{array}\]</span>
Y llamamos
<span class="math display">\[u_3  = v_3 - \mathrm{proy}_{U_2}(v_3) = \left(\begin{array}{c} -1\\ -1\\ 0\\ -1 \end{array}\right)  - \left( \begin{array}{c@{}} - \frac{1}{2}\\ -1\\ - \frac{1}{2}\\ -1 \end{array} \right)  =  \left( \begin{array}{c@{}} - \frac{1}{2}\\ 0\\ \frac{1}{2}\\ 0 \end{array} \right) \]</span></li>
<li>Construimos:
<span class="math display">\[U_3 = \mathcal{L}(\{u_1, u_2, u_3\}) = \mathcal{L}(\left\{\left( \begin{array}{c@{}} -1\\ -1\\ -1\\ -1 \end{array} \right) , \left( \begin{array}{c@{}} 1\\ -1\\ 1\\ -1 \end{array} \right) , \left( \begin{array}{c@{}} - \frac{1}{2}\\ 0\\ \frac{1}{2}\\ 0 \end{array} \right) \right\})\]</span>
Entonces
<span class="math display">\[\begin{array}{rcl}\mathrm{proy}_{U_3}(v_4) &amp; = &amp; \frac{\langle v_4, u_1 \rangle}{\langle u_1, u_1 \rangle} u_1+\frac{\langle v_4, u_2 \rangle}{\langle u_2, u_2 \rangle} u_2+\frac{\langle v_4, u_3 \rangle}{\langle u_3, u_3 \rangle} u_3 \\ &amp; = &amp; \frac{0}{4} \left( \begin{array}{c@{}} -1\\ -1\\ -1\\ -1 \end{array} \right) +\frac{0}{4} \left( \begin{array}{c@{}} 1\\ -1\\ 1\\ -1 \end{array} \right) +\frac{1}{\frac{1}{2}} \left( \begin{array}{c@{}} - \frac{1}{2}\\ 0\\ \frac{1}{2}\\ 0 \end{array} \right)  \\ &amp; = &amp; \left( \begin{array}{c@{}} -1\\ 0\\ 1\\ 0 \end{array} \right) \\\end{array}\]</span>
Y llamamos
<span class="math display">\[u_4  = v_4 - \mathrm{proy}_{U_3}(v_4) = \left(\begin{array}{c} -1\\ 1\\ 1\\ -1 \end{array}\right)  - \left( \begin{array}{c@{}} -1\\ 0\\ 1\\ 0 \end{array} \right)  =  \left( \begin{array}{c@{}} 0\\ 1\\ 0\\ -1 \end{array} \right) \]</span></li>
</ul>
<p>Por tanto, la base ortogonal a la que llegamos es
<span class="math display">\[\mathcal{B}&#39; = \{u_i\} = \left\{\left( \begin{array}{c@{}} -1\\ -1\\ -1\\ -1 \end{array} \right) , \left( \begin{array}{c@{}} 1\\ -1\\ 1\\ -1 \end{array} \right) , \left( \begin{array}{c@{}} - \frac{1}{2}\\ 0\\ \frac{1}{2}\\ 0 \end{array} \right) , \left( \begin{array}{c@{}} 0\\ 1\\ 0\\ -1 \end{array} \right) \right\}\]</span></p>
<p><em>Fase 2</em></p>
<p>Ahora debemos multiplicar cada vector <span class="math inline">\(u_i\)</span> en <span class="math inline">\(\mathcal{B}&#39;\)</span> por el inverso de su norma, y llegamos a los vectores <span class="math inline">\(\frac{1}{\|u_i\|}u_i\)</span>, que nos forman la base ortonormal siguiente:
<span class="math display">\[\begin{array}{rcl}\mathcal{B}&#39;&#39; &amp; = &amp; \left\{\frac{1}{2}\left(\begin{array}{c} -1\\ -1\\ -1\\ -1 \end{array}\right), \frac{1}{2}\left(\begin{array}{c} 1\\ -1\\ 1\\ -1 \end{array}\right), \frac{1}{\frac{\sqrt{2}}{2}}\left(\begin{array}{c} \frac{-1}{2}\\ 0\\ \frac{1}{2}\\ 0 \end{array}\right), \frac{1}{\sqrt{2}}\left(\begin{array}{c} 0\\ 1\\ 0\\ -1 \end{array}\right)\right\} = \\ &amp; = &amp; \left\{\left(\begin{array}{c} \frac{-1}{2}\\ \frac{-1}{2}\\ \frac{-1}{2}\\ \frac{-1}{2} \end{array}\right), \left(\begin{array}{c} \frac{1}{2}\\ \frac{-1}{2}\\ \frac{1}{2}\\ \frac{-1}{2} \end{array}\right), \left(\begin{array}{c} \frac{-\sqrt{2}}{2}\\ 0\\ \frac{\sqrt{2}}{2}\\ 0 \end{array}\right), \left(\begin{array}{c} 0\\ \frac{\sqrt{2}}{2}\\ 0\\ \frac{-\sqrt{2}}{2} \end{array}\right)\right\} \\\end{array}\]</span></p>
<hr />
</div>
<div id="ortho-matrix" class="section level2" number="5.7">
<h2 number="5.7"><span class="header-section-number">5.7</span> Qué es una matriz ortogonal y una aplicación ortogonal</h2>
<p>Una matriz cuadrada <span class="math inline">\(Q\)</span> se llama <strong>ortogonal</strong> si <span class="math inline">\(Q^{\text{t}}Q = I\)</span> o, equivalentemente, <span class="math inline">\(Q^{-1} = Q^{\text{t}}\)</span>.</p>
<p>Es decir, una matriz ortogonal es aquella cuya inversa es su propia traspuesta.</p>
<blockquote>
<p>Una matriz <span class="math inline">\(A\in\mathcal{M}_n(\mathbb{R})\)</span> es ortogonal si, y sólo si, sus columnas forman una base <em>ortonormal</em> de <span class="math inline">\(\mathbb{R}^n\)</span>.</p>
</blockquote>
<p>Un endomorfismo <span class="math inline">\(f:V\to V\)</span> se llama <strong>ortogonal</strong> si respeta el producto escalar, es decir, si <span class="math inline">\(\langle\cdot,\cdot\rangle\)</span> es el producto escalar en <span class="math inline">\(V\)</span>, entonces <span class="math inline">\(\langle f(u), f(v) \rangle = \langle u, v \rangle\)</span> para todo <span class="math inline">\(u,v\in V\)</span>.</p>
<p>Como la aplicación ortogonal conserva el producto escalar, también conserva todas las cantidades que hemos definido a partir de él: <a href="espacios-euclídeos.html#norm">la norma, la distancia</a> y <a href="espacios-euclídeos.html#ortho">el ángulo</a> entre vectores de <span class="math inline">\(V\)</span>: <span class="math inline">\(\|f(v)\| = \|v\|\)</span>, <span class="math inline">\(d(f(u), f(v)) = d(u,v)\)</span> y <span class="math inline">\(\mathrm{ang}(f(u),f(v)) = \mathrm{ang}(u, v)\)</span> para todo <span class="math inline">\(u,v\in V\)</span>.</p>
<blockquote>
<p>Una aplicación <span class="math inline">\(f:V\to V\)</span> es ortogonal si, y sólo si, la imagen de toda base ortonormal es de nuevo una base ortonormal de <span class="math inline">\(V\)</span>.</p>
</blockquote>
<p>¿Qué relación existe entre matrices ortogonales y aplicaciones ortogonales?</p>
<blockquote>
<p>Sea <span class="math inline">\(f:V\to V\)</span> una aplicación lineal y sea <span class="math inline">\(A\)</span> su matriz asociada respecto a una base ortonormal de <span class="math inline">\(V\)</span>. Entonces <span class="math inline">\(f\)</span> es ortogonal si, y solo si, la matriz <span class="math inline">\(A\)</span> es ortogonal.</p>
</blockquote>
<hr />
<p><strong>Ejemplo</strong></p>
<ul>
<li><p>La matriz asociada a la rotación.</p></li>
<li><p>Matriz formada por base ortonormal del apartado anterior.</p></li>
</ul>
<hr />
</div>
<div id="diag-ortho" class="section level2" number="5.8">
<h2 number="5.8"><span class="header-section-number">5.8</span> Qué es la diagonalización ortogonal</h2>
<ul>
<li>Definición de matriz diagonalizable ortogonalmente</li>
<li>Teorema diagonalización ortogonal</li>
</ul>
<hr />
<p><strong>Ejemplo</strong></p>
<hr />
</div>
<div id="diag-ortho2" class="section level2" number="5.9">
<h2 number="5.9"><span class="header-section-number">5.9</span> Qué matrices son diagonalizables ortogonalmente</h2>
<ul>
<li>Teoremas que relacionan matrices simétricas con diagonabilidad ortogonal</li>
<li>Procedimiento diagonalización ortogonal matriz simétrica</li>
</ul>
<hr />
<p><strong>Ejemplo</strong></p>
<hr />

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="diagonalización.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="problems.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Algebra_Lineal.pdf", "Algebra_Lineal.epub"],
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
