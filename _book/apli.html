<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Aplicaciones lineales | Preguntas y respuestas de Álgebra Lineal</title>
  <meta name="description" content="En este libro vamos a recopilar algunas de las preguntas y dudas más frecuentes en los temas de Álgebra Lineal, con ejemplos resueltos, y acompañados de la teoría necesaria para comprender los resultados." />
  <meta name="generator" content="bookdown 0.16 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Aplicaciones lineales | Preguntas y respuestas de Álgebra Lineal" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="En este libro vamos a recopilar algunas de las preguntas y dudas más frecuentes en los temas de Álgebra Lineal, con ejemplos resueltos, y acompañados de la teoría necesaria para comprender los resultados." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Aplicaciones lineales | Preguntas y respuestas de Álgebra Lineal" />
  
  <meta name="twitter:description" content="En este libro vamos a recopilar algunas de las preguntas y dudas más frecuentes en los temas de Álgebra Lineal, con ejemplos resueltos, y acompañados de la teoría necesaria para comprender los resultados." />
  

<meta name="author" content="Domingo López" />


<meta name="date" content="2020-05-25" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ev.html"/>
<link rel="next" href="diagonalización.html"/>
<script src="libs/header-attrs-2.1/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Preguntas y respuestas de Álgebra Lineal</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introducción</a></li>
<li class="chapter" data-level="2" data-path="ev.html"><a href="ev.html"><i class="fa fa-check"></i><b>2</b> Espacios Vectoriales</a>
<ul>
<li class="chapter" data-level="2.1" data-path="ev.html"><a href="ev.html#subesp"><i class="fa fa-check"></i><b>2.1</b> Qué es un subespacio vectorial</a></li>
<li class="chapter" data-level="2.2" data-path="ev.html"><a href="ev.html#indep"><i class="fa fa-check"></i><b>2.2</b> Qué es un sistema de vectores linealmente independiente</a></li>
<li class="chapter" data-level="2.3" data-path="ev.html"><a href="ev.html#gen"><i class="fa fa-check"></i><b>2.3</b> Qué es un sistema generador y el subespacio generado por un conjunto de vectores</a></li>
<li class="chapter" data-level="2.4" data-path="ev.html"><a href="ev.html#sistgenabase"><i class="fa fa-check"></i><b>2.4</b> Cómo extraemos una base a partir de un sistema generador de un (sub)espacio vectorial</a></li>
<li class="chapter" data-level="2.5" data-path="ev.html"><a href="ev.html#base"><i class="fa fa-check"></i><b>2.5</b> Cómo encontrar la base (y la dimensión) para un subespacio vectorial</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="ev.html"><a href="ev.html#partiendo-de-las-ecuaciones-paramétricas"><i class="fa fa-check"></i><b>2.5.1</b> Partiendo de las ecuaciones paramétricas</a></li>
<li class="chapter" data-level="2.5.2" data-path="ev.html"><a href="ev.html#partiendo-de-las-ecuaciones-cartesianas"><i class="fa fa-check"></i><b>2.5.2</b> Partiendo de las ecuaciones cartesianas</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="ev.html"><a href="ev.html#param2cartesian"><i class="fa fa-check"></i><b>2.6</b> Cómo convertir entre ecuaciones cartesianas y paramétricas de un subespacio vectorial</a></li>
<li class="chapter" data-level="2.7" data-path="ev.html"><a href="ev.html#interseccion"><i class="fa fa-check"></i><b>2.7</b> Cómo hallar la intersección de dos subespacios vectoriales</a></li>
<li class="chapter" data-level="2.8" data-path="ev.html"><a href="ev.html#union"><i class="fa fa-check"></i><b>2.8</b> ¿Es la unión de subespacios un subespacio?</a></li>
<li class="chapter" data-level="2.9" data-path="ev.html"><a href="ev.html#suma"><i class="fa fa-check"></i><b>2.9</b> Cómo hallar la suma de dos subespacios vectoriales</a></li>
<li class="chapter" data-level="2.10" data-path="ev.html"><a href="ev.html#th-dim"><i class="fa fa-check"></i><b>2.10</b> Qué dice el teorema de la dimensión</a></li>
<li class="chapter" data-level="2.11" data-path="ev.html"><a href="ev.html#supl"><i class="fa fa-check"></i><b>2.11</b> Cómo calcular el subespacio suplementario de uno dado</a></li>
<li class="chapter" data-level="2.12" data-path="ev.html"><a href="ev.html#coord"><i class="fa fa-check"></i><b>2.12</b> Cómo calcular las coordenadas de un vector con respecto a una base dada</a></li>
<li class="chapter" data-level="2.13" data-path="ev.html"><a href="ev.html#cambiobase"><i class="fa fa-check"></i><b>2.13</b> Cómo calcular la matriz de cambio de base entre dos bases de un mismo espacio vectorial</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="apli.html"><a href="apli.html"><i class="fa fa-check"></i><b>3</b> Aplicaciones lineales</a>
<ul>
<li class="chapter" data-level="3.1" data-path="apli.html"><a href="apli.html#prop-apli"><i class="fa fa-check"></i><b>3.1</b> Qué propiedades básicas tienen las aplicaciones lineales</a></li>
<li class="chapter" data-level="3.2" data-path="apli.html"><a href="apli.html#matriz-apli"><i class="fa fa-check"></i><b>3.2</b> Cuál es la matriz asociada a una aplicación lineal en unas bases dadas</a></li>
<li class="chapter" data-level="3.3" data-path="apli.html"><a href="apli.html#cambiobase-apli"><i class="fa fa-check"></i><b>3.3</b> Cómo influye un cambio de base en la matriz asociada a una aplicación lineal</a></li>
<li class="chapter" data-level="3.4" data-path="apli.html"><a href="apli.html#nucleo"><i class="fa fa-check"></i><b>3.4</b> Qué es y cómo determinar el núcleo de una aplicación lineal</a></li>
<li class="chapter" data-level="3.5" data-path="apli.html"><a href="apli.html#inyectividad"><i class="fa fa-check"></i><b>3.5</b> Cómo podemos identificar una aplicación lineal inyectiva</a></li>
<li class="chapter" data-level="3.6" data-path="apli.html"><a href="apli.html#imagen"><i class="fa fa-check"></i><b>3.6</b> Cómo calcular el subespacio imagen de una aplicación lineal</a></li>
<li class="chapter" data-level="3.7" data-path="apli.html"><a href="apli.html#sobrey"><i class="fa fa-check"></i><b>3.7</b> Cómo identificar si una aplicación lineal es sobreyectiva</a></li>
<li class="chapter" data-level="3.8" data-path="apli.html"><a href="apli.html#isomorfismo"><i class="fa fa-check"></i><b>3.8</b> Qué es un isomorfismo</a></li>
<li class="chapter" data-level="3.9" data-path="apli.html"><a href="apli.html#imagenU"><i class="fa fa-check"></i><b>3.9</b> Cómo determinar la imagen de un subespacio vectorial</a></li>
<li class="chapter" data-level="3.10" data-path="apli.html"><a href="apli.html#rango-nulidad"><i class="fa fa-check"></i><b>3.10</b> A qué se llama rango y nulidad de la aplicación lineal</a></li>
<li class="chapter" data-level="3.11" data-path="apli.html"><a href="apli.html#th-dim-nucleo"><i class="fa fa-check"></i><b>3.11</b> Qué dice el teorema de la dimensión para núcleo e imagen</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="diagonalización.html"><a href="diagonalización.html"><i class="fa fa-check"></i><b>4</b> Diagonalización</a>
<ul>
<li class="chapter" data-level="4.1" data-path="diagonalización.html"><a href="diagonalización.html#eigenvalue"><i class="fa fa-check"></i><b>4.1</b> Qué son los autovalores de un endomorfismo y de una matriz</a></li>
<li class="chapter" data-level="4.2" data-path="diagonalización.html"><a href="diagonalización.html#eigenspace"><i class="fa fa-check"></i><b>4.2</b> Cómo calculamos los autovectores asociados a un autovalor</a></li>
<li class="chapter" data-level="4.3" data-path="diagonalización.html"><a href="diagonalización.html#diagonalizable"><i class="fa fa-check"></i><b>4.3</b> Cómo sabemos si un endomorfismo o una matriz es diagonalizable</a></li>
<li class="chapter" data-level="4.4" data-path="diagonalización.html"><a href="diagonalización.html#pot-matrix"><i class="fa fa-check"></i><b>4.4</b> Si una matriz es diagonalizable, cómo podemos hallar sus potencias</a></li>
<li class="chapter" data-level="4.5" data-path="diagonalización.html"><a href="diagonalización.html#th-cayley"><i class="fa fa-check"></i><b>4.5</b> Para qué podemos utilizar el Teorema de Cayley-Hamilton</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="espeuc.html"><a href="espeuc.html"><i class="fa fa-check"></i><b>5</b> Espacios Euclídeos</a>
<ul>
<li class="chapter" data-level="5.1" data-path="espeuc.html"><a href="espeuc.html#norm"><i class="fa fa-check"></i><b>5.1</b> Qué son las normas y distancias</a></li>
<li class="chapter" data-level="5.2" data-path="espeuc.html"><a href="espeuc.html#ortho"><i class="fa fa-check"></i><b>5.2</b> Qué significa el concepto de ortogonalidad</a></li>
<li class="chapter" data-level="5.3" data-path="espeuc.html"><a href="espeuc.html#compl-ortho"><i class="fa fa-check"></i><b>5.3</b> Qué es el complemento ortogonal de un subespacio</a></li>
<li class="chapter" data-level="5.4" data-path="espeuc.html"><a href="espeuc.html#proyec"><i class="fa fa-check"></i><b>5.4</b> Cómo calculamos la proyección de un vector sobre un subespacio</a></li>
<li class="chapter" data-level="5.5" data-path="espeuc.html"><a href="espeuc.html#ortho-basis"><i class="fa fa-check"></i><b>5.5</b> Qué es y qué utilidad tiene una base ortonormal</a></li>
<li class="chapter" data-level="5.6" data-path="espeuc.html"><a href="espeuc.html#gram-schmidt"><i class="fa fa-check"></i><b>5.6</b> Cómo construimos una base ortonormal</a></li>
<li class="chapter" data-level="5.7" data-path="espeuc.html"><a href="espeuc.html#ortho-matrix"><i class="fa fa-check"></i><b>5.7</b> Qué es una matriz ortogonal y una aplicación ortogonal</a></li>
<li class="chapter" data-level="5.8" data-path="espeuc.html"><a href="espeuc.html#diag-ortho"><i class="fa fa-check"></i><b>5.8</b> Qué es la diagonalización ortogonal</a></li>
<li class="chapter" data-level="5.9" data-path="espeuc.html"><a href="espeuc.html#diag-ortho2"><i class="fa fa-check"></i><b>5.9</b> Qué matrices son diagonalizables ortogonalmente</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="problems.html"><a href="problems.html"><i class="fa fa-check"></i><b>6</b> Problemas Resueltos</a>
<ul>
<li class="chapter" data-level="6.1" data-path="problems.html"><a href="problems.html#prob-ev"><i class="fa fa-check"></i><b>6.1</b> Espacios Vectoriales</a></li>
<li class="chapter" data-level="6.2" data-path="problems.html"><a href="problems.html#prob-apli"><i class="fa fa-check"></i><b>6.2</b> Aplicaciones lineales</a></li>
<li class="chapter" data-level="6.3" data-path="problems.html"><a href="problems.html#prob-diag"><i class="fa fa-check"></i><b>6.3</b> Diagonalización</a></li>
<li class="chapter" data-level="6.4" data-path="problems.html"><a href="problems.html#prob-espeuclideo"><i class="fa fa-check"></i><b>6.4</b> Espacios Euclídeos</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://dominlopez.netlify.app" target="blank">Escrito por Domingo López</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Preguntas y respuestas de Álgebra Lineal</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="apli" class="section level1" number="3">
<h1 number="3"><span class="header-section-number">3</span> Aplicaciones lineales</h1>
<p>Consideremos dos <a href="ev.html#ev">espacios vectoriales</a> <span class="math inline">\(V\)</span> y <span class="math inline">\(W\)</span> sobre el mismo cuerpo <span class="math inline">\(\mathbb{K}\)</span>, y una aplicación <span class="math inline">\(f:V\to W\)</span> entre ellos.</p>
<p>Diremos que <span class="math inline">\(f\)</span> es una <strong>aplicación lineal</strong> si verifica las siguientes dos condiciones:</p>
<ul>
<li><span class="math inline">\(f(v_1 + v_2) = f(v_1) + f(v_2)\)</span> para todo <span class="math inline">\(v_1, v_2\in V\)</span>.</li>
<li><span class="math inline">\(f(c\cdot v) = c\cdot f(v)\)</span> para todo <span class="math inline">\(c\in\mathbb{K},\,v\in V\)</span>.</li>
</ul>
<p>Una aplicación lineal cuyo dominio y codominio sean iguales (<span class="math inline">\(V = W\)</span>) se llama <strong>endomorfismo</strong>.</p>
<hr />
<p><strong>Ejemplo</strong></p>
<p>Existen muchos ejemplos de aplicaciones lineales:</p>
<ul>
<li>La aplicación 0, la identidad… son aplicaciones lineales de forma trivial.</li>
<li>Las rotaciones de vectores en <span class="math inline">\(\mathbb{R}^n\)</span> son aplicaciones lineales.</li>
<li>Sobre el espacio vectorial <span class="math inline">\(\mathcal{C}([a, b])\)</span> de funciones continuas y derivables en un intervalo <span class="math inline">\([a, b]\)</span>, tanto el operador derivada <span class="math inline">\(f\to f&#39;\)</span> como el operador integral <span class="math inline">\(f \to \int_a^b f\)</span>, son aplicaciones lineales.</li>
</ul>
<hr />
<p><strong>¿Qué preguntas vamos a responder en este capítulo?</strong></p>
<ul>
<li><a href="apli.html#prop-apli">¿Qué propiedades básicas tienen las aplicaciones lineales?</a></li>
<li><a href="apli.html#matriz-apli">¿Cuál es la matriz asociada a una aplicación lineal en unas bases dadas?</a></li>
<li><a href="apli.html#cambiobase-apli">¿Cómo influye un cambio de base en la matriz asociada a una aplicación lineal?</a></li>
<li><a href="apli.html#nucleo">¿Qué es y cómo determinar el núcleo de una aplicación lineal?</a></li>
<li><a href="apli.html#inyectividad">¿Cómo podemos identificar una aplicación lineal inyectiva?</a></li>
<li><a href="apli.html#imagen">¿Cómo calcular el subespacio imagen de una aplicación lineal?</a></li>
<li><a href="apli.html#sobrey">¿Cómo identificar si una aplicación lineal es sobreyectiva?</a></li>
<li><a href="apli.html#isomorfismo">¿Qué es un isomorfismo?</a></li>
<li><a href="apli.html#imagenU">¿Cómo determinar la imagen de un subespacio vectorial?</a></li>
<li><a href="apli.html#rango-nulidad">¿A qué se llama rango y nulidad de la aplicación lineal?</a></li>
<li><a href="apli.html#th-dim-nucleo">¿Qué dice el teorema de la dimensión para núcleo e imagen?</a></li>
</ul>
<div id="prop-apli" class="section level2" number="3.1">
<h2 number="3.1"><span class="header-section-number">3.1</span> Qué propiedades básicas tienen las aplicaciones lineales</h2>
<p>Vamos a revisar aquí algunas de las propiedades básicas de las aplicaciones lineales entre espacios vectoriales.</p>
<p>Consideremos una aplicación lineal <span class="math inline">\(f:V\to W\)</span>.</p>
<blockquote>
<ul>
<li><span class="math inline">\(f(0_V) = 0_W\)</span></li>
<li><span class="math inline">\(f(-v) = -f(v),\quad v\in V\)</span></li>
<li><span class="math inline">\(f(v_1 - v_2) = f(v_1) - f(v_2),\quad v_1, v_2\in V\)</span></li>
<li><span class="math inline">\(f(\alpha_1 v_1 + \ldots \alpha_n v_n) = \alpha_1 f(v_1) + \ldots + \alpha_n f(v_n),\quad \alpha_i\in\mathbb{K},v_i\in V\)</span></li>
</ul>
</blockquote>
<p>Además:</p>
<blockquote>
<ul>
<li>Si <span class="math inline">\(U\)</span> es un <a href="ev.html#subesp">subespacio</a> de <span class="math inline">\(V\)</span>, entonces <span class="math inline">\(f(U)\)</span> es un subespacio de <span class="math inline">\(W\)</span>. Análogamente, si <span class="math inline">\(S\)</span> es subespacio de <span class="math inline">\(W\)</span>, su preimagen <span class="math inline">\(f^{-1}(S)\)</span> es también un subespacio de <span class="math inline">\(V\)</span>.</li>
<li>Si <span class="math inline">\(\mathcal{G} = \{u_1,\ldots,u_m\}\)</span> es un <a href="ev.html#gen">sistema generador</a> de un subespacio <span class="math inline">\(U\)</span> de <span class="math inline">\(V\)</span>, entonces <span class="math inline">\(f(\mathcal{G}) = \{f(u_1),\ldots,f(u_m)\}\)</span> es un sistema generador de <span class="math inline">\(f(U)\)</span>.</li>
</ul>
</blockquote>
<p>Y, por último,</p>
<blockquote>
<p>Si <span class="math inline">\(f:V \to W\)</span> y <span class="math inline">\(g:W \to U\)</span> son dos aplicaciones lineales, entonces su composición <span class="math inline">\(g \circ f :V \to U\)</span> también es una aplicación lineal.</p>
</blockquote>
</div>
<div id="matriz-apli" class="section level2" number="3.2">
<h2 number="3.2"><span class="header-section-number">3.2</span> Cuál es la matriz asociada a una aplicación lineal en unas bases dadas</h2>
<blockquote>
<p>Si tenemos una matriz <span class="math inline">\(A\in \mathcal{M}_{mn}(\mathbb{R})\)</span>, podemos definir una aplicación lineal <span class="math inline">\(f_A\)</span> entre <span class="math inline">\(\mathbb{R}^n\)</span> y <span class="math inline">\(\mathbb{R}^m\)</span> de la forma:</p>
<p><span class="math display">\[f_A(v) = A\cdot v,\quad v\in\mathbb{R}^n\]</span></p>
</blockquote>
<p>En este resultado, podemos cambiar el cuerpo <span class="math inline">\(\mathbb{R}\)</span> de los números reales por cualquier otro cuerpo.</p>
<p>Este resultado nos habla de una forma de construir aplicaciones lineales, mediante el producto por una matriz que tenga las dimensiones adecuadas.</p>
<p>Un resultado más interesante es el siguiente, que nos dice que TODA aplicación lineal viene definida por el producto con una matriz:</p>
<blockquote>
<p><strong>Matriz asociada a una aplicación lineal</strong>:
Sea <span class="math inline">\(f:V\to W\)</span> una aplicación lineal. Fijemos dos bases <span class="math inline">\(\mathcal{B}_V\)</span> y <span class="math inline">\(\mathcal{B}_W\)</span> en dichos espacios, respectivamente. Entonces existe una matriz <span class="math inline">\(A\in\mathcal{M}_{mn}(\mathbb{R})\)</span> tal que si <span class="math inline">\(w = f(v)\)</span> entonces <span class="math inline">\([w]_{\mathcal{B}_W} = A\cdot [v]_{\mathcal{B}_V}\)</span> para todo <span class="math inline">\(v\in V\)</span>.</p>
</blockquote>
<p>Esto significa que, fijando las bases, podemos encontrar una matriz <span class="math inline">\(A\)</span> de forma que para calcular la imagen de un vector <span class="math inline">\(v\in V\)</span>, basta con tomar sus <a href="ev.html#coord">coordenadas</a> en la base <span class="math inline">\(\mathcal{B}_V\)</span>, que representamos por <span class="math inline">\([v]_{\mathcal{B}_V}\)</span>, y multiplicarlas por <span class="math inline">\(A\)</span>, para obtener las coordenadas de <span class="math inline">\(f(v)\)</span> en la base correspondiente del <em>codominio</em> <span class="math inline">\(W\)</span>, las cuales se denotan por <span class="math inline">\([f(v)]_{\mathcal{B}_W}\)</span>.</p>
<p><strong>Definición (Matriz asociada a aplicación lineal) </strong> A la matriz <span class="math inline">\(A\)</span> que nos proporciona este resultado la llamamos <strong>matriz asociada</strong> a <span class="math inline">\(f\)</span> en las <a href="#sisgenabase">bases</a> <span class="math inline">\(\mathcal{B}_V\)</span> y <span class="math inline">\(\mathcal{B}_W\)</span>.</p>
<p>Hay que notar que la matriz <span class="math inline">\(A\)</span> está determinada siempre y cuando fijemos las dos bases antes dichas.</p>
<p>Pero, ¿cómo determinamos la matriz <span class="math inline">\(A\)</span>?</p>
<p>Necesitamos fijar las dos bases de antemano:
<span class="math display">\[\mathcal{B}_V = \{v_1,\ldots,v_n\}\]</span>
<span class="math display">\[\mathcal{B}_W = \{w_1,\ldots,w_m\}\]</span></p>
<p>El procedimiento general para construir la matriz <span class="math inline">\(A\)</span> es el que sigue. Para determinar la columna <span class="math inline">\(j\)</span>-ésima de <span class="math inline">\(A\)</span>:</p>
<ul>
<li>Tomamos el vector <span class="math inline">\(j\)</span>-ésimo de la base de <span class="math inline">\(V\)</span>: <span class="math inline">\(v_j\)</span>.</li>
<li>Calculamos su imagen <span class="math inline">\(y_j = f(v_j)\)</span>.</li>
<li>Calculamos las coordenadas de <span class="math inline">\(y_j\)</span> en la base <span class="math inline">\(\mathcal{B}_W\)</span>.
<span class="math display">\[[y_j]_{\mathcal{B}_W} = \left(
\begin{array}{c}
a_{1, j}\\
a_{2, j}\\
\vdots\\
a_{m, j}
\end{array}
\right) \Leftrightarrow
y_j = a_{1,j} w_1 + a_{2,j}w_2 + \ldots + a_{m, j} w_m\]</span></li>
<li>Esas coordenadas son la columna <span class="math inline">\(j\)</span> de la matriz <span class="math inline">\(A\)</span>.</li>
</ul>
<p>Vamos a pasar todo esto a notación matricial, para encontrar una forma cómoda de resolver este problema.</p>
<p>Llamemos <span class="math inline">\(B_2\)</span> a la matriz formada, por columnas, por las coordenadas de los vectores de <span class="math inline">\(\mathcal{B}_W\)</span> en la base canónica: <span class="math inline">\(B_2 = \left(w_1|w_2|\ldots|w_m\right)\)</span>.</p>
<p>Llamamos <span class="math inline">\(Y = \left(y_1|y_2|\ldots|y_n\right) = \left(f(v_1)|f(v_2)|\ldots|f(v_n)\right)\)</span>.</p>
<p>Entonces, la expresión anterior se puede escribir matricialmente como <span class="math inline">\(Y = B_2\cdot A\)</span>, siendo <span class="math inline">\(A\)</span> la matriz asociada a la aplicación lineal. Por tanto, podemos despejar <span class="math inline">\(A = B_2^{-1} Y\)</span>.</p>
<p>Por tanto, para calcular <span class="math inline">\(A\)</span> de forma directa, podemos realizar Gauss-Jordan partiendo de <span class="math inline">\((B_2 | Y )\)</span> hasta lograr <span class="math inline">\((I_m | A)\)</span>.</p>
<p><strong>Caso particular: Base canónica en <span class="math inline">\(V\)</span> y <span class="math inline">\(W\)</span></strong></p>
<p>En este caso, la matriz asociada a la aplicación lineal es
<span class="math display">\[A = Y = \left(f(v_1)|f(v_2)|\ldots|f(v_n)\right)\]</span>
puesto que los vectores de la base canónica puestos por columnas forman la matriz identidad.</p>
<p>De hecho, en la situación de la base canónica, lo más rápido es fijarse en los coeficientes de cada una de las variables <span class="math inline">\(x,y,z,\ldots\)</span> o <span class="math inline">\(x_1,x_2,\ldots\)</span>, según sea el caso, y ponerlos por columnas. Así, para formar la matriz <span class="math inline">\(A\)</span> asociada a la aplicación lineal, tomaríamos como primera columna los coeficientes de la <span class="math inline">\(x\)</span>, en la segunda, los coeficientes de la <span class="math inline">\(y\)</span>, y así sucesivamente con el resto de variables.</p>
<hr />
<p><strong>Ejemplo</strong></p>
<p>Consideremos la aplicación <span class="math inline">\(f:V=\mathbb{R}^{3}\to W=\mathbb{R}^{3}\)</span> dada por:</p>
<p><span class="math display">\[f \left(\begin{array}{c}
x\\
y\\
z
\end{array}\right)
  = \left( \begin{array}{c}
x+ y+ z\\
x-2y\\
2x-y+ z\\
\end{array} \right)\]</span></p>
<p>Como hemos visto, para encontrar su matriz asociada en las bases canónicas de <span class="math inline">\(v\)</span> y <span class="math inline">\(W\)</span>, basta con mirar los coeficientes de <span class="math inline">\(x,y,\ldots\)</span>, y ponerlos por columnas:</p>
<p><span class="math display">\[A =  \left(\begin{array}{ccc}
1 &amp; 1 &amp; 1\\
1 &amp; -2 &amp; 0\\
2 &amp; -1 &amp; 1
\end{array}\right)
 \]</span></p>
<p>Esto significa que si tenemos un vector <span class="math inline">\(v\in V\)</span> expresado en coordenadas en la base canónica, entonces <span class="math inline">\(f(v) = A\ v\)</span>, también expresado en las coordenadas canónicas de <span class="math inline">\(W\)</span>.</p>
<p>Consideremos ahora dos bases distintas de la canónica tanto en <span class="math inline">\(V\)</span> como <span class="math inline">\(W\)</span>:</p>
<p><span class="math display">\[\mathcal{B}_{1} = \{v_i\} = \left\{\left(
\begin{array}{c@{}}
-1\\
1\\
-1
\end{array}
\right)
, \left(
\begin{array}{c@{}}
0\\
-1\\
1
\end{array}
\right)
, \left(
\begin{array}{c@{}}
-1\\
-1\\
-1
\end{array}
\right)
\right\}\]</span><span class="math display">\[\mathcal{B}_{2} = \{w_i\} = \left\{\left(
\begin{array}{c@{}}
1\\
0\\
2
\end{array}
\right)
, \left(
\begin{array}{c@{}}
1\\
2\\
0
\end{array}
\right)
, \left(
\begin{array}{c@{}}
1\\
0\\
1
\end{array}
\right)
\right\}\]</span></p>
<p>Vamos a calcular la matriz <span class="math inline">\(A&#39;\)</span> asociada a <span class="math inline">\(f\)</span> en estas dos bases. Debemos calcular:</p>
<p><span class="math display">\[Y= (f(v_1)|\ldots|f(v_n))\]</span>
<span class="math display">\[B_2 = (w_1|\ldots|w_m)\]</span></p>
<p>Aplicando <span class="math inline">\(f\)</span> sucesivamente a los vectores de <span class="math inline">\(\mathcal{B}_1\)</span>, tenemos que
<span class="math display">\[Y = \left( \begin{array}{ccc@{}} -1 &amp; 0 &amp; -3\\ -3 &amp; 2 &amp; 1\\ -4 &amp; 2 &amp; -2 \end{array} \right) \]</span>
y
<span class="math display">\[B_2 = \left( \begin{array}{ccc@{}} 1 &amp; 1 &amp; 1\\ 0 &amp; 2 &amp; 0\\ 2 &amp; 0 &amp; 1 \end{array} \right) \]</span></p>
<p>Luego podemos obtener <span class="math inline">\(A&#39;\)</span> como <span class="math inline">\(B_2^{-1} Y\)</span>, que resolvemos por Gauss-Jordan:
<span class="math display">\[\left( \begin{array}{ccc|ccc} 1 &amp; 1 &amp; 1 &amp; -1 &amp; 0 &amp; -3\\ 0 &amp; 2 &amp; 0 &amp; -3 &amp; 2 &amp; 1\\ 2 &amp; 0 &amp; 1 &amp; -4 &amp; 2 &amp; -2 \end{array} \right) \sim\left( \begin{array}{ccc|ccc} 1 &amp; 0 &amp; 0 &amp; - \frac{9}{2} &amp; 3 &amp; \frac{3}{2}\\ 0 &amp; 1 &amp; 0 &amp; - \frac{3}{2} &amp; 1 &amp; \frac{1}{2}\\ 0 &amp; 0 &amp; 1 &amp; 5 &amp; -4 &amp; -5 \end{array} \right) \]</span>
Y de aquí que la nueva matriz, asociada a <span class="math inline">\(f\)</span> en las nuevas bases, sea:
<span class="math display">\[A&#39; = \left( \begin{array}{ccc@{}} - \frac{9}{2} &amp; 3 &amp; \frac{3}{2}\\ - \frac{3}{2} &amp; 1 &amp; \frac{1}{2}\\ 5 &amp; -4 &amp; -5 \end{array} \right) \]</span></p>
<hr />
</div>
<div id="cambiobase-apli" class="section level2" number="3.3">
<h2 number="3.3"><span class="header-section-number">3.3</span> Cómo influye un cambio de base en la matriz asociada a una aplicación lineal</h2>
<p>Supongamos que tenemos una aplicación lineal <span class="math inline">\(f:V\to W\)</span> y que tenemos prefijadas unas bases <span class="math inline">\(\mathcal{B}_V\)</span> y <span class="math inline">\(\mathcal{B}_W\)</span> y, por tanto, tenemos determinada la matriz <span class="math inline">\(A\)</span>, asociada a <span class="math inline">\(f\)</span> en esas bases.</p>
<p>Consideremos unas nuevas bases <span class="math inline">\(\mathcal{B}&#39;_V\)</span> y <span class="math inline">\(\mathcal{B}&#39;_W\)</span> y nos preguntamos cuál será la matriz <span class="math inline">\(A&#39;\)</span> asociada a <span class="math inline">\(f\)</span> en dichas bases.</p>
<p>Para saber hallar <span class="math inline">\(A&#39;\)</span>, nos basamos en dos resultados teóricos.</p>
<p>El primero de ellos nos relaciona los <a href="ev.html#cambiobase">cambios de base</a> con las aplicaciones lineales:</p>
<blockquote>
<p><strong>Cambio de base como aplicación lineal</strong>:
Un <strong>cambio de base</strong> entre dos bases <span class="math inline">\(\mathcal{B}_V\)</span> y <span class="math inline">\(\mathcal{B}&#39;_V\)</span> en un espacio vectorial <span class="math inline">\(V\)</span> se corresponde con la aplicación lineal <strong>identidad</strong> <span class="math inline">\(\mathrm{id}_V:V \to V\)</span>, donde en el dominio hemos considerado la base <span class="math inline">\(\mathcal{B}_V\)</span> y en el codominio la base <span class="math inline">\(\mathcal{B}&#39;_V\)</span>. Además, la matriz asociada a <span class="math inline">\(\mathrm{id}_V\)</span> en esta situación es justo la del cambio de base <span class="math inline">\(P_{\mathcal{B}_V \to \mathcal{B}&#39;_V}\)</span>.</p>
</blockquote>
<p>Es decir, podemos considerar que un cambio de base no es más que la aplicación de la función identidad en el espacio vectorial, donde en dominio y codominio hemos considerado bases distintas.</p>
<p>El otro resultado teórico nos relaciona la composición de aplicaciones lineales (que <a href="apli.html#prop-apli">es de nuevo una aplicación lineal</a>) con sus matrices asociadas:</p>
<blockquote>
<p><strong>Composición de aplicaciones lineales</strong>:
Si <span class="math inline">\(f: V \to W\)</span> y <span class="math inline">\(g:W \to U\)</span> son dos aplicaciones lineales, con matrices asociadas <span class="math inline">\(A_f\)</span> y <span class="math inline">\(A_g\)</span>, respectivamente, habiendo fijado bases en <span class="math inline">\(V\)</span>, <span class="math inline">\(W\)</span> y <span class="math inline">\(U\)</span>, entonces la aplicación lineal composición de <span class="math inline">\(f\)</span> y <span class="math inline">\(g\)</span>, <span class="math inline">\(g\circ f:V\to U\)</span>, tiene como matriz asociada a <span class="math inline">\(A_{g \circ f} = A_g \cdot A_f\)</span>.</p>
</blockquote>
<p>Luego si componemos dos aplicaciones lineales, <em>habiendo fijado bases en cada caso</em>, la matriz asociada a la composición es el producto de las matrices individuales.</p>
<p>Con estos dos resultados, ya estamos en condiciones de estudiar cómo influye un cambio de base en la matriz de la aplicación lineal.</p>
<p>Veamos el siguiente esquema, donde denotamos <span class="math inline">\(V_{\mathcal{B}}\)</span> que estamos considerando la base <span class="math inline">\(\mathcal{B}\)</span> en el espacio <span class="math inline">\(V\)</span>:
<span class="math display">\[
\begin{array}{ccccccc}
V_{\mathcal{B}&#39;_V} &amp;
\xrightarrow{\mathrm{id}_V} &amp; V_{\mathcal{B}_V} &amp; \xrightarrow{f} &amp; W_{\mathcal{B}_W} &amp; \xrightarrow{\mathrm{id}_W} &amp; W_{\mathcal{B}&#39;_W} \\
 &amp; P_{\mathcal{B}&#39;_V \to \mathcal{B}_V} &amp; &amp; A &amp; &amp; P_{\mathcal{B}_W \to \mathcal{B}&#39;_W} &amp; \\
\end{array}
\]</span></p>
<p>Llamemos, por comodidad, <span class="math inline">\(P = P_{\mathcal{B}&#39;_V \to \mathcal{B}_V}\)</span> y <span class="math inline">\(Q = P_{\mathcal{B}_W \to \mathcal{B}&#39;_W}\)</span>. Recordemos que tanto <span class="math inline">\(P\)</span> como <span class="math inline">\(Q\)</span> se pueden calcular <a href="ev.html#cambiobase">de forma sencilla</a>.</p>
<p>De esta forma, vemos que si fijamos las nuevas bases, entonces la aplicación <span class="math inline">\(f\)</span> resultante equivale a la <span class="math inline">\(f\)</span> anterior, a la que precedemos y sucedemos con la aplicación identidad dentro de <span class="math inline">\(V\)</span> y <span class="math inline">\(W\)</span>, respectivamente, puesto que <span class="math inline">\(f = \mathrm{id}_W\circ f \circ \mathrm{id}_V\)</span>.</p>
<p>Teniendo en cuenta los resultados teóricos anteriores, esto quiere decir que <span class="math inline">\(A&#39; = Q\ A\ P\)</span>.</p>
<p>Como consecuencia, tenemos además que</p>
<blockquote>
<p>Todas las matrices asociadas a una misma aplicación lineal <span class="math inline">\(f\)</span> en distintas bases son equivalentes.</p>
</blockquote>
<hr />
<p><strong>Ejemplo</strong></p>
<p>Continuemos con el ejemplo de <a href="apli.html#matriz-apli">la sección anterior</a>. Sabemos que la aplicación <span class="math inline">\(f\)</span> allí definida tenía por matriz asociada:
<span class="math display">\[A = \left( \begin{array}{ccc@{}} - \frac{9}{2} &amp; 3 &amp; \frac{3}{2}\\ - \frac{3}{2} &amp; 1 &amp; \frac{1}{2}\\ 5 &amp; -4 &amp; -5 \end{array} \right) \]</span></p>
<p>Consideremos ahora dos bases distintas tanto en <span class="math inline">\(V\)</span> como <span class="math inline">\(W\)</span>:
<span class="math display">\[\mathcal{B}&#39;_{1} =\left\{\left(
\begin{array}{c@{}}
1\\
-1\\
1
\end{array}
\right)
, \left(
\begin{array}{c@{}}
0\\
-1\\
-1
\end{array}
\right)
, \left(
\begin{array}{c@{}}
0\\
-1\\
1
\end{array}
\right)
\right\}\]</span><span class="math display">\[\mathcal{B}&#39;_{2} =\left\{\left(
\begin{array}{c@{}}
2\\
2\\
2
\end{array}
\right)
, \left(
\begin{array}{c@{}}
1\\
0\\
2
\end{array}
\right)
, \left(
\begin{array}{c@{}}
0\\
0\\
1
\end{array}
\right)
\right\}\]</span></p>
<p>Vamos a aplicar lo anterior para encontrar la matriz <span class="math inline">\(A&#39;\)</span> asociada a <span class="math inline">\(f\)</span> en las nuevas bases.</p>
<p>Para ello, sabemos que <span class="math inline">\(A&#39; = Q\ A\ P\)</span>, donde <span class="math inline">\(P\)</span> es la matriz de cambio de base de <span class="math inline">\(\mathcal{B}&#39;_1\)</span> a <span class="math inline">\(\mathcal{B}_1\)</span> y <span class="math inline">\(Q\)</span> es el cambio de <span class="math inline">\(\mathcal{B}_2\)</span> a <span class="math inline">\(\mathcal{B}&#39;_2\)</span>.</p>
<p>Si llamamos <span class="math inline">\(B_1\)</span>, <span class="math inline">\(B&#39;_1\)</span>, <span class="math inline">\(B_2\)</span> y <span class="math inline">\(B&#39;_2\)</span> a las matrices que resultan de poner por columnas los vectores de <span class="math inline">\(\mathcal{B}_1\)</span>, <span class="math inline">\(\mathcal{B}&#39;_1\)</span>, <span class="math inline">\(\mathcal{B}_2\)</span> y <span class="math inline">\(\mathcal{B}&#39;_2\)</span>, respectivamente, podemos calcular <span class="math inline">\(P\)</span> y <span class="math inline">\(Q\)</span> de la siguiente manera, según <a href="ev.html#cambiobase">ya hemos visto</a>:
<span class="math display">\[P = B_1^{-1}\ B&#39;_1,\quad\quad Q = {B&#39;_2}^{-1}\ B_2\]</span></p>
<p>Hacemos Gauss-Jordan partiendo de <span class="math inline">\((B_1 | B&#39;_1)\)</span> hasta llegar a <span class="math inline">\((I_n | P)\)</span>, y partiendo de <span class="math inline">\((B&#39;_2 | B_2)\)</span> hasta <span class="math inline">\((I_m | Q)\)</span>, obteniendo:
<span class="math display">\[P = \left( \begin{array}{ccc@{}} -1 &amp; -1 &amp; 0\\ 0 &amp; -1 &amp; 1\\ 0 &amp; 1 &amp; 0 \end{array} \right) ,\quad\quad\ Q = \left( \begin{array}{ccc@{}} 0 &amp; 1 &amp; 0\\ 1 &amp; -1 &amp; 1\\ 0 &amp; 0 &amp; -1 \end{array} \right) \]</span></p>
<p>De ahí:
<span class="math display">\[\begin{array}{rcl}A&#39; &amp; = &amp; Q\ A\ P = \\ &amp; = &amp; \left( \begin{array}{ccc@{}} 0 &amp; 1 &amp; 0\\ 1 &amp; -1 &amp; 1\\ 0 &amp; 0 &amp; -1 \end{array} \right) \left( \begin{array}{ccc@{}} - \frac{9}{2} &amp; 3 &amp; \frac{3}{2}\\ - \frac{3}{2} &amp; 1 &amp; \frac{1}{2}\\ 5 &amp; -4 &amp; -5 \end{array} \right) \left( \begin{array}{ccc@{}} -1 &amp; -1 &amp; 0\\ 0 &amp; -1 &amp; 1\\ 0 &amp; 1 &amp; 0 \end{array} \right)  = \\ &amp; = &amp; \left( \begin{array}{ccc@{}} \frac{3}{2} &amp; 1 &amp; 1\\ -2 &amp; -4 &amp; -2\\ 5 &amp; 6 &amp; 4 \end{array} \right) \\\end{array}\]</span></p>
<hr />
</div>
<div id="nucleo" class="section level2" number="3.4">
<h2 number="3.4"><span class="header-section-number">3.4</span> Qué es y cómo determinar el núcleo de una aplicación lineal</h2>
<p><strong>Definición (Núcleo de una aplicación lineal) </strong> Llamamos <strong>núcleo</strong> de una aplicación lineal <span class="math inline">\(f:V \to W\)</span>, y lo denotamos por <span class="math inline">\(\mathrm{Ker}\ f\)</span>, al conjunto de aquellos vectores <span class="math inline">\(v\in V\)</span> tales que <span class="math inline">\(f(v) = 0_W\)</span>:</p>
<p><span class="math display">\[\mathrm{Ker}\ f = \{v\in V:f(v) = 0_W\}\]</span></p>
<p>El primer resultado teórico interesante es:</p>
<blockquote>
<p><span class="math inline">\(\mathrm{Ker}\ f \ne\varnothing\)</span>, puesto que, al menos, <span class="math inline">\(0_V\in\mathrm{Ker}\ f\)</span>, como <a href="apli.html#prop-apli">hemos visto antes</a>.</p>
</blockquote>
<p>Podemos decir todavía más:</p>
<blockquote>
<p><strong>El núcleo es un subespacio</strong>:
Dada una aplicación lineal <span class="math inline">\(f:V\to W\)</span>, su núcleo <span class="math inline">\(\mathrm{Ker}\ f\)</span> es un subespacio vectorial de <span class="math inline">\(V\)</span>.</p>
</blockquote>
<p>Por tanto, para operar con el núcleo, podemos hacerlo como hemos visto en <a href="ev.html#ev">el capítulo acerca de espacios vectoriales</a>: podemos calcular <a href="ev.html#gen">un sistema generador</a>, <a href="ev.html#base">determinar una base y su dimensión</a>.</p>
<p>¿Qué relación tiene el núcleo de <span class="math inline">\(f\)</span> con su matriz asociada?</p>
<p>Supongamos que fijamos las bases en <span class="math inline">\(V\)</span> y <span class="math inline">\(W\)</span> y que la matriz asociada a <span class="math inline">\(f\)</span> en esas bases es <span class="math inline">\(A\)</span>.</p>
<p>Entonces, si <span class="math inline">\(v\in V\)</span> está en el núcleo, será que <span class="math inline">\(f(v) = 0_W\)</span>, luego las coordenadas de <span class="math inline">\(f(v)\)</span> en la base de <span class="math inline">\(W\)</span> son todas cero: <span class="math inline">\([f(v)]_{\mathcal{B}_W} = 0\)</span>.</p>
<p>Pero como conocemos la matriz asociada a <span class="math inline">\(f\)</span>, entonces sabemos que <span class="math inline">\([f(v)]_{\mathcal{B}_W} = A\ [v]_{\mathcal{B}_V}\)</span>.</p>
<p>En resumen, <span class="math inline">\(v\in\mathrm{Ker}\ f\)</span> si, y sólo si <span class="math inline">\(A\ [v]_{\mathcal{B}_V} = 0\)</span>, es decir, si y sólo si las coordenadas de <span class="math inline">\(v\)</span> son solución del sistema de ecuaciones lineales homogéneo <span class="math inline">\(Ax = 0\)</span>.</p>
<blockquote>
<p><span class="math inline">\(\mathrm{Ker}\ f\)</span> coincide con el subespacio de las soluciones del sistema <span class="math inline">\(Ax = 0\)</span>.</p>
</blockquote>
<p>Esto también implica que <strong>las ecuaciones cartesianas de <span class="math inline">\(\mathrm{Ker}\ f\)</span> son <span class="math inline">\(Ax = 0\)</span></strong>. Por tanto, podemos aplicar <a href="ev.html#base">lo que ya hemos visto</a> para calcular una base del núcleo de <span class="math inline">\(f\)</span>.</p>
<hr />
<p><strong>Ejemplo</strong></p>
<p>Seguimos con el ejemplo de la aplicación <span class="math inline">\(f:V=\mathbb{R}^{3}\to W=\mathbb{R}^{3}\)</span> dada por:</p>
<p><span class="math display">\[f \left(\begin{array}{c}
x\\
y\\
z
\end{array}\right)
  = \left( \begin{array}{c}
x+ y+ z\\
x-2y\\
2x-y+ z\\
\end{array} \right)\]</span></p>
<p>Como hemos visto, su matriz asociada es:</p>
<p><span class="math display">\[A =  \left(\begin{array}{ccc}
1 &amp; 1 &amp; 1\\
1 &amp; -2 &amp; 0\\
2 &amp; -1 &amp; 1
\end{array}\right)
 \]</span></p>
<p>Usamos esa matriz <span class="math inline">\(A\)</span> para construir el sistema homogéneo:
<span class="math display">\[\begin{array}{rrrcr} x &amp; + y &amp; + z &amp; = &amp; 0\\ x &amp; -2y &amp;  &amp; = &amp; 0\\ 2x &amp; -y &amp; + z &amp; = &amp; 0\\ \end{array}\]</span>
que se corresponde con las ecuaciones cartesianas de <span class="math inline">\(\mathrm{Ker}\ f\)</span> (podíamos haber hecho directamente <span class="math inline">\(f(v) = 0\)</span> usando la definición de <span class="math inline">\(f\)</span>).</p>
<p>Usaremos <a href="ev.html#base">lo que hemos visto ya</a> para convertir esas ecuaciones a forma paramétrica (usando eliminación Gaussiana), y así conseguir un sistema generador y <a href="#sisgenabase">una base</a>:
<span class="math display">\[\begin{array}{rrrcr} x &amp; + y &amp; + z &amp; = &amp; 0\\ x &amp; -2y &amp;  &amp; = &amp; 0\\ 2x &amp; -y &amp; + z &amp; = &amp; 0\\ \end{array}\Leftrightarrow\ \left(\begin{array}{c} x\\ y\\ z \end{array}\right)  = \alpha\left(\begin{array}{c} - \frac{2}{3}\\ - \frac{1}{3}\\ 1 \end{array}\right) {}\]</span></p>
<p>Luego
<span class="math display">\[\mathcal{B}_{\mathrm{Ker}\ f} = \left\{\left( \begin{array}{c@{}} - \frac{2}{3}\\ - \frac{1}{3}\\ 1 \end{array} \right) \right\}\]</span></p>
<hr />
</div>
<div id="inyectividad" class="section level2" number="3.5">
<h2 number="3.5"><span class="header-section-number">3.5</span> Cómo podemos identificar una aplicación lineal inyectiva</h2>
<p>Recordemos que una aplicación <span class="math inline">\(f:X\to Y\)</span> es <strong>inyectiva</strong> si y sólo si <span class="math inline">\(f(x_1)\ne f(x_2)\)</span> siempre que <span class="math inline">\(x_1\ne x_2\)</span>, con <span class="math inline">\(x_1, x_2\in X\)</span>.</p>
<p>Hay una forma de caracterizar las aplicaciones lineales inyectivas:</p>
<blockquote>
<p><strong>Caracterización de la inyectividad</strong>:
La aplicación lineal <span class="math inline">\(f:V\to W\)</span> es inyectiva si, y sólo si, <span class="math inline">\(\mathrm{Ker}\ f = \{0\}\)</span>, es decir, si y sólo si <span class="math inline">\(\mathrm{dim}(\mathrm{Ker}\ f) = 0\)</span>.</p>
</blockquote>
<p>Un resultado interesante nos presenta una relación entre la inyectividad de <span class="math inline">\(f\)</span> y las dimensiones de los espacios <span class="math inline">\(V\)</span> y <span class="math inline">\(W\)</span>:</p>
<blockquote>
<p>Si la aplicación lineal <span class="math inline">\(f:V\to W\)</span> es inyectiva, entonces se verifica que <span class="math inline">\(\mathrm{dim}(V)\le\mathrm{dim}(W)\)</span>.</p>
</blockquote>
<p>El recíproco no es cierto, no siempre que tengamos <span class="math inline">\(\mathrm{dim}(V)\le\mathrm{dim}(W)\)</span> la aplicación puede ser inyectiva. Por ejemplo, la aplicación cero <span class="math inline">\(0:\mathbb{R}^2\to\mathbb{R}^3\)</span>, que asocia a todo vector el vector 0 del codominio, no puede ser inyectiva, a pesar de que la dimensión del dominio es menor que la del codominio.</p>
<p>Podemos decir todavía algún resultado teórico que nos proporciona más información acerca de cómo identificar aplicaciones lineales inyectivas:</p>
<blockquote>
<p>Una aplicación <span class="math inline">\(f:V\to W\)</span> es inyectiva si, y sólo si, la imagen de todo <a href="ev.html#indep">sistema linealmente independiente</a> es también un sistema linealmente independiente.</p>
</blockquote>
<blockquote>
<p>Si <span class="math inline">\(V\)</span> es de dimensión finita, entonces la aplicación lineal <span class="math inline">\(f:V\to W\)</span> es inyectiva si, y sólo si, <span class="math inline">\(\mathrm{dim}(V) = \mathrm{dim}(\mathrm{Im}\ f)\)</span></p>
</blockquote>
<hr />
<p><strong>Ejemplo</strong></p>
<p>En el ejemplo de <a href="apli.html#nucleo">la sección anterior</a>, tenemos que <span class="math inline">\(\mathrm{dim}(\mathrm{Ker}\ f) = 1\)</span>, luego <span class="math inline">\(f\)</span> <strong>no es inyectiva</strong>, ya que en ese caso debería ser <span class="math inline">\(\mathrm{dim}(\mathrm{Ker}\ f) = 0\)</span>.</p>
<p>Consideremos otra aplicación <span class="math inline">\(g:\mathbb{R}^{3}\to \mathbb{R}^{3}\)</span> dada por:
<span class="math display">\[g \left(\begin{array}{c} x\\ y\\ z \end{array}\right)  = \left( \begin{array}{ccc@{}} 2 &amp; -1 &amp; 0\\ 1 &amp; 3 &amp; 0\\ 2 &amp; 0 &amp; 4 \end{array} \right) \ \left(\begin{array}{c} x\\ y\\ z \end{array}\right)  = \left(\begin{array}{c} 2x-y\\ x+ 3y\\ 2x+ 4z\\ \end{array}\right)\]</span></p>
<p>Podemos estudiar su núcleo para comprobar si es inyectiva:
<span class="math display">\[\mathrm{Ker}\ g =\left\{\left(\begin{array}{c} x\\ y\\ z \end{array}\right) \in\mathbb{R}^{3}:\begin{array}{ccr} 2x-y &amp; = &amp; 0\\ x+ 3y &amp; = &amp; 0\\ 2x+ 4z &amp; = &amp; 0\\ \end{array}\right\}\]</span></p>
<p>Resolvemos el sistema homogéneo para llegar a que
<span class="math display">\[\left\{\begin{array}{rrrcr} 2x &amp; -y &amp;  &amp; = &amp; 0\\ x &amp; + 3y &amp;  &amp; = &amp; 0\\ 2x &amp;  &amp; + 4z &amp; = &amp; 0\\ \end{array}\right.\Rightarrow\left(\begin{array}{c} x\\ y\\ z \end{array}\right)  = \left(\begin{array}{c} 0\\ 0\\ 0 \end{array}\right) \]</span></p>
<p>Luego <span class="math inline">\(\mathrm{Ker}\ g=\{0\}\)</span>, y así <span class="math inline">\(g\)</span> es inyectiva.</p>
<hr />
</div>
<div id="imagen" class="section level2" number="3.6">
<h2 number="3.6"><span class="header-section-number">3.6</span> Cómo calcular el subespacio imagen de una aplicación lineal</h2>
<p><strong>Definición (Imagen de una aplicación lineal) </strong> Llamamos <strong>imagen de la aplicación lineal</strong> <span class="math inline">\(f:V\to W\)</span> a:
<span class="math display">\[\mathrm{Im}\ f = \{w\in W: \text{existe }v\in V \text{ con }f(v) = w\} = f(V)\]</span></p>
<p>Análogamente a lo que pasaba con <a href="apli.html#nucleo">el núcleo de una aplicación lineal</a>, tenemos:</p>
<blockquote>
<p><strong>La imagen es un subespacio vectorial</strong>:
Si <span class="math inline">\(f:V\to W\)</span> es una aplicación lineal, entonces <span class="math inline">\(\mathrm{Im}\ f\)</span> es un subespacio vectorial de <span class="math inline">\(W\)</span>.</p>
</blockquote>
<p>Por tanto, podemos estudiarlo con todas las <a href="ev.html#ev">herramientas que conocemos</a>.</p>
<p>¿Cómo calculamos <span class="math inline">\(\mathrm{Im}\ f\)</span>?</p>
<p><a href="apli.html#prop-apli">Recordemos</a> que si <span class="math inline">\(\mathcal{G}\)</span> es un <a href="ev.html#gen">sistema generador</a> de un subespacio <span class="math inline">\(U\)</span> de <span class="math inline">\(V\)</span>, entonces <span class="math inline">\(f(\mathcal{G})\)</span> es un sistema generador de <span class="math inline">\(f(U)\)</span>.</p>
<p>En concreto, tomando una base <span class="math inline">\(\mathcal{B}\)</span> de <span class="math inline">\(V\)</span>, su imagen <span class="math inline">\(f(\mathcal{B})\)</span> es un sistema generador de <span class="math inline">\(\mathrm{Im}\ f\)</span>. Basta, por tanto, aplicar <span class="math inline">\(f\)</span> a cada vector de <span class="math inline">\(\mathcal{B}\)</span> y con eso construimos un sistema generador del que podemos <a href="#sisgenabase">eliminar los vectores linealmente dependientes para obtener una base</a> de <span class="math inline">\(\mathrm{Im}\ f\)</span>.</p>
<p>En consecuencia:</p>
<blockquote>
<p><strong>Sistema generador de <span class="math inline">\(\mathrm{Im}\ f\)</span></strong>:
Sea <span class="math inline">\(f\)</span> una aplicación lineal entre dos espacios <span class="math inline">\(V\)</span> y <span class="math inline">\(W\)</span>, y sea <span class="math inline">\(A\)</span> la matriz asociada a <span class="math inline">\(f\)</span>, una vez que hemos fijado dos bases en <span class="math inline">\(V\)</span> y <span class="math inline">\(W\)</span>. Entonces <span class="math inline">\(\mathrm{Im}\ f\)</span> es el subespacio de <span class="math inline">\(W\)</span> generado por los vectores columna que forman la matriz <span class="math inline">\(A\)</span>.</p>
</blockquote>
<hr />
<p><strong>Ejemplo</strong></p>
<p>Vamos a estudiar la imagen de las dos aplicaciones <span class="math inline">\(f\)</span> y <span class="math inline">\(g\)</span> del <a href="apli.html#inyectividad">ejemplo anterior</a>.</p>
<p>Para <span class="math inline">\(f\)</span>, tenemos que <span class="math inline">\(\mathrm{Im}\ f\)</span> está generado por los vectores columnas de la matriz <span class="math inline">\(A\)</span>, luego un sistema generador de <span class="math inline">\(\mathrm{Im}\ f\)</span> será:
<span class="math display">\[\mathcal{G}_{\mathrm{Im}\ f} = \left\{\left( \begin{array}{c@{}} 1\\ 1\\ 2 \end{array} \right) , \left( \begin{array}{c@{}} 1\\ -2\\ -1 \end{array} \right) , \left( \begin{array}{c@{}} 1\\ 0\\ 1 \end{array} \right) \right\}\]</span></p>
<p>A partir de él, <a href="#sisgenabase">eliminando los vectores que sean linealmente dependientes</a>, encontramos una base de <span class="math inline">\(\mathrm{Im}\ f\)</span>:
<span class="math display">\[\mathcal{B}_{\mathrm{Im}\ f} = \left\{\left( \begin{array}{c@{}} 1\\ 1\\ 2 \end{array} \right) , \left( \begin{array}{c@{}} 1\\ -2\\ -1 \end{array} \right) \right\}\]</span></p>
<p>Luego <span class="math inline">\(\mathrm{dim}(\mathrm{Im}\ f) = 2\)</span>.</p>
<p>Vayamos ahora con la aplicación <span class="math inline">\(g\)</span>. Con el mismo razonamiento, sabemos que
<span class="math display">\[\mathcal{G}_{\mathrm{Im}\ g} = \left\{\left( \begin{array}{c@{}} 2\\ 1\\ 2 \end{array} \right) , \left( \begin{array}{c@{}} -1\\ 3\\ 0 \end{array} \right) , \left( \begin{array}{c@{}} 0\\ 0\\ 4 \end{array} \right) \right\}\]</span>
es un sistema generador de <span class="math inline">\(\mathrm{Im}\ g\)</span>.</p>
<p>Igual que antes, podemos encontrar una base de <span class="math inline">\(\mathrm{Im}\ g\)</span>:
<span class="math display">\[\mathcal{B}_{\mathrm{Im}\ g} = \left\{\left( \begin{array}{c@{}} 2\\ 1\\ 2 \end{array} \right) , \left( \begin{array}{c@{}} -1\\ 3\\ 0 \end{array} \right) , \left( \begin{array}{c@{}} 0\\ 0\\ 4 \end{array} \right) \right\}\]</span></p>
<p>Entonces <span class="math inline">\(\mathrm{dim}(\mathrm{Im}\ g) = 3\)</span>. Esto nos dice que <span class="math inline">\(\mathrm{Im}\ g = W\)</span>.</p>
<hr />
</div>
<div id="sobrey" class="section level2" number="3.7">
<h2 number="3.7"><span class="header-section-number">3.7</span> Cómo identificar si una aplicación lineal es sobreyectiva</h2>
<p>Recordemos que una aplicación <span class="math inline">\(f:X\to Y\)</span> se dice <strong>sobreyectiva</strong> si, para cada <span class="math inline">\(y\in Y\)</span>, existe un <span class="math inline">\(x\in X\)</span> tal que <span class="math inline">\(f(x) = y\)</span>, es decir, si <span class="math inline">\(f(X) = Y\)</span>.</p>
<p>En cuanto a aplicaciones lineales, tenemos el siguiente resultado, consecuencia de lo anterior:</p>
<blockquote>
<p><strong>Caracterización de la sobreyectividad</strong>:
La aplicación lineal <span class="math inline">\(f:V\to W\)</span> es sobreyectiva si <span class="math inline">\(f(V) = \mathrm{Im}\ f = W\)</span>, y esto es equivalente a decir que <span class="math inline">\(\mathrm{dim}(\mathrm{Im}\ f) = \mathrm{dim}(W)\)</span>.</p>
</blockquote>
<p>Una propiedad adicional, con relación a las dimensiones de <span class="math inline">\(V\)</span> y de <span class="math inline">\(W\)</span>:</p>
<blockquote>
<p>Si la aplicación lineal <span class="math inline">\(f:V\to W\)</span> es sobreyectiva, entonces <span class="math inline">\(\mathrm{dim}(V)\ge\mathrm{dim}(W)\)</span>.</p>
</blockquote>
<hr />
<p><strong>Ejemplo</strong></p>
<p>En el <a href="apli.html#imagen">ejemplo anterior</a>, estudiamos las imágenes de las aplicaciones <span class="math inline">\(f\)</span> y <span class="math inline">\(g\)</span> de los ejemplos.</p>
<p>Si aplicamos el resultado teórico de antes, llegamos a que:</p>
<ul>
<li><span class="math inline">\(f\)</span> no es sobreyectiva, pues <span class="math inline">\(\mathrm{dim}(\mathrm{Im}\ f) = 2 \ne 3 = \mathrm{dim}(W)\)</span>.</li>
<li><span class="math inline">\(g\)</span> sí es sobreyectiva, pues <span class="math inline">\(\mathrm{dim}(\mathrm{Im}\ g) = 3 = \mathrm{dim}(W)\)</span>.</li>
</ul>
<hr />
</div>
<div id="isomorfismo" class="section level2" number="3.8">
<h2 number="3.8"><span class="header-section-number">3.8</span> Qué es un isomorfismo</h2>
<p><strong>Definición (Isomorfismo y automorfismo) </strong> Un <strong>isomorfismo</strong> es una aplicación lineal <a href="#inyectiva">inyectiva</a> y <a href="apli.html#sobrey">sobreyectiva</a>.</p>
<p>Un <strong>automorfismo</strong> es un isomorfismo donde dominio y codominio son el mismo espacio <span class="math inline">\(V\)</span>.</p>
<p><strong>Algunas propiedades básicas de los isomorfismos</strong></p>
<ul>
<li>La composición de isomorfismos es un isomorfismo.</li>
<li>La aplicación inversa de un isomorfismo es también un isomorfismo</li>
</ul>
<p>Cuando, además, estamos hablando de espacios de dimensión finita, tenemos los siguientes resultados:</p>
<blockquote>
<ul>
<li><p>Una aplicación lineal <span class="math inline">\(f:V\to W\)</span> es un isomorfismo si, y sólo si, <span class="math inline">\(\mathrm{dim}(V) = \mathrm{dim}(W)\)</span>.</p></li>
<li><p>Una aplicación <span class="math inline">\(f:V\to V\)</span> es un <em>automorfismo</em> si, y sólo si, o bien es inyectiva o bien es sobreyectiva.</p></li>
</ul>
</blockquote>
<p>Este último resultado nos dice que en un <em>endomorfismo</em>, basta con ver si la aplicación es <a href="apli.html#inyectividad">inyectiva</a> o <a href="apli.html#sobrey">sobreyectiva</a> para tener que es un isomorfismo.</p>
<hr />
<p><strong>Ejemplo</strong></p>
<p>Si miramos las aplicaciones <span class="math inline">\(f\)</span> y <span class="math inline">\(g\)</span> de <a href="apli.html#nucleo">las secciones anteriores</a>, entonces podemos confirmar que <span class="math inline">\(g\)</span> es un automorfismo, mientras que <span class="math inline">\(f\)</span> no lo es, ya que no es ni inyectiva ni sobreyectiva.</p>
<hr />
</div>
<div id="imagenU" class="section level2" number="3.9">
<h2 number="3.9"><span class="header-section-number">3.9</span> Cómo determinar la imagen de un subespacio vectorial</h2>
<p>Este problema es realmente un <em>caso particular</em> de <a href="apli.html#imagen">cómo calcular la imagen de una aplicación lineal</a>.</p>
<p>Tanto en esa sección como en la de <a href="apli.html#prop-apli">propiedades</a>, vimos que si <span class="math inline">\(U\)</span> es un <a href="ev.html#gen">subespacio vectorial generado</a> por los vectores de <span class="math inline">\(\mathcal{G}=\{u_1,\ldots,u_k\}\)</span>, entonces <span class="math inline">\(f(\mathcal{G}) = \{f(u_1),\ldots,f(u_k)\}\)</span> es un sistema generador de <span class="math inline">\(f(U)\)</span>.</p>
<p>Por tanto, si deseamos calcular la imagen de un subespacio <span class="math inline">\(U\)</span>, los pasos a seguir serán:</p>
<ul>
<li>A partir de sus ecuaciones (si se dan), <a href="ev.html#base">encontrar un sistema generador o una base</a> de <span class="math inline">\(U\)</span>.</li>
<li>Calcular la imagen, mediante la aplicación <span class="math inline">\(f\)</span>, de los vectores de la base de <span class="math inline">\(U\)</span>. Por <a href="apli.html#prop-apli">lo anterior</a>, esto es un sistema generador de <span class="math inline">\(f(U)\)</span>.</li>
<li><a href="#sisgenabase">Eliminar los vectores linealmente dependientes</a> de ese sistema generador, para obtener una base de <span class="math inline">\(f(U)\)</span>.</li>
</ul>
<hr />
<p><strong>Ejemplo</strong></p>
<p>Consideremos el subespacio <span class="math inline">\(U\)</span> dado por
<span class="math display">\[U = \left\{\left(\begin{array}{c} x\\ y\\ z \end{array}\right) \in\mathbb{R}^{3}:\begin{array}{ccr} -x- \frac{1}{2}y+ z &amp; = &amp; 0\\ \end{array}\right\}\]</span></p>
<p>Queremos calcular <span class="math inline">\(f(U)\)</span> y <span class="math inline">\(g(U)\)</span>, siendo <span class="math inline">\(f\)</span> y <span class="math inline">\(g\)</span> las de <a href="apli.html#nucleo">los ejemplos anteriores</a>.</p>
<p>El primer paso es <a href="ev.html#base">calcular una base</a> de <span class="math inline">\(U\)</span>. Para ello, pasamos las ecuaciones cartesianas de <span class="math inline">\(U\)</span> a paramétricas, que nos dan un sistema generador, resolviendo el sistema de ecuaciones por Gauss. A partir del sistema generador, ya podríamos proceder, o podemos calcular una base de <span class="math inline">\(U\)</span>.</p>
<p>En nuestro caso,
<span class="math display">\[\mathcal{B}_U = \left\{\left( \begin{array}{c@{}} -2\\ 2\\ -1 \end{array} \right) , \left( \begin{array}{c@{}} 1\\ 0\\ 1 \end{array} \right) \right\}\]</span></p>
<p>Comenzamos por calcular <span class="math inline">\(f(U)\)</span>. Debemos calcular la imagen de los vectores de la base de <span class="math inline">\(U\)</span> con la aplicación <span class="math inline">\(f\)</span>:
<span class="math display">\[f(\mathcal{B}_U) = \left\{\left( \begin{array}{c@{}} -1\\ -6\\ -7 \end{array} \right) , \left( \begin{array}{c@{}} 2\\ 1\\ 3 \end{array} \right) \right\}\]</span></p>
<p>Si <a href="#sisgenabase">eliminamos los vectores linealmente dependientes</a> de <span class="math inline">\(f(\mathcal{B}_U)\)</span>, nos queda una base de <span class="math inline">\(f(U)\)</span>:
<span class="math display">\[\mathcal{B}_{f(U)} = \left\{\left( \begin{array}{c@{}} -1\\ -6\\ -7 \end{array} \right) , \left( \begin{array}{c@{}} 2\\ 1\\ 3 \end{array} \right) \right\}\]</span></p>
<p>Repetimos el proceso con la aplicación <span class="math inline">\(g\)</span>. Calculamos:
<span class="math display">\[g(\mathcal{B}_U) = \left\{\left( \begin{array}{c@{}} -6\\ 4\\ -8 \end{array} \right) , \left( \begin{array}{c@{}} 2\\ 1\\ 6 \end{array} \right) \right\}\]</span></p>
<p>Como sabemos que <span class="math inline">\(g\)</span> es un <a href="apli.html#isomorfismo">isomorfismo</a>, sabemos que la imagen de un sistema linealmente independiente es también un sistema linealmente independiente. Luego <span class="math inline">\(\mathcal{B}_{g(U)} = g(\mathcal{B}_U)\)</span>. Si no recordáramos este resultado, deberíamos intentar eliminar los vectores linealmente dependientes en <span class="math inline">\(g(\mathcal{B}_U)\)</span> para así obtener la base.</p>
<hr />
</div>
<div id="rango-nulidad" class="section level2" number="3.10">
<h2 number="3.10"><span class="header-section-number">3.10</span> A qué se llama rango y nulidad de la aplicación lineal</h2>
<p><strong>Definición (Rango) </strong> Se llama <strong>rango</strong> de una aplicación lineal <span class="math inline">\(f:V\to W\)</span> a la dimensión de la <a href="apli.html#imagen">imagen</a> de <span class="math inline">\(f\)</span>: <span class="math inline">\(\mathrm{rg}(f) = \mathrm{dim}(\mathrm{Im}\ f)\)</span>.</p>
<p><strong>Definición (Nulidad) </strong> Se llama <strong>nulidad</strong> de una aplicación lineal <span class="math inline">\(f:V\to W\)</span> a la dimensión del <a href="apli.html#nucleo">núcleo</a> de <span class="math inline">\(f\)</span>: <span class="math inline">\(\mathrm{nul}(f) = \mathrm{dim}(\mathrm{Ker}\ f)\)</span>.</p>
<p>De forma análoga, se pueden definir rango y nulidad para <strong>matrices</strong>, puesto que tenemos <a href="#matrix-apli">una importante relación entre matrices y aplicaciones lineales</a>.</p>
<p><strong>Definición (Rango y nulidad de una matriz) </strong> Dada una matriz <span class="math inline">\(A\)</span>, su <strong>rango</strong> <span class="math inline">\(\mathrm{rg}(A)\)</span> es la dimensión del subespacio generado por los vectores que forman sus columnas, y su <strong>nulidad</strong> <span class="math inline">\(\mathrm{nul}(A)\)</span> es la dimensión del subespacio vectorial de las soluciones del sistema de ecuaciones lineales <span class="math inline">\(A\ v = 0\)</span>.</p>
<p>Un resultado importante, debido a que <a href="apli.html#cambiobase-apli">todas las matrices asociadas a una misma aplicación lineal son equivalentes</a>, es que todas tienen el mismo rango y la misma nulidad, y coinciden con el rango y nulidad de <span class="math inline">\(f\)</span>.</p>
<p>Por tanto, para calcular rango y nulidad de <span class="math inline">\(f\)</span>, bastará con estudiar el rango y nulidad de cualquiera de sus expresiones matriciales en unas bases fijadas de <span class="math inline">\(V\)</span> y <span class="math inline">\(W\)</span>.</p>
<hr />
<p><strong>Ejemplo</strong></p>
<p>Vamos a calcular el rango y la nulidad de las aplicaciones <span class="math inline">\(f\)</span> y <span class="math inline">\(g\)</span> que estamos estudiando en los <a href="apli.html#nucleo">ejemplos anteriores</a>.</p>
<p>El caso fácil es el de <span class="math inline">\(g\)</span>, que era un <a href="apli.html#isomorfismo">isomorfismo</a>. Luego:</p>
<ul>
<li><span class="math inline">\(\mathrm{nul}(g) = \mathrm{dim}(\mathrm{Ker}\ g) = \mathrm{dim}(\{0\}) = 0\)</span>, por ser <span class="math inline">\(g\)</span> <a href="apli.html#inyectividad">inyectiva</a>.</li>
<li><span class="math inline">\(\mathrm{rg}(g) = \mathrm{dim}(\mathrm{Im}\ g) = \mathrm{dim}(W) = 3\)</span>, por ser <span class="math inline">\(g\)</span> <a href="apli.html#sobrey">sobreyectiva</a>.</li>
</ul>
<p>Y lo mismo se aplica para sus matrices asociadas.</p>
<p>En cuanto a <span class="math inline">\(f\)</span>, recopilando la información que tenemos:</p>
<ul>
<li>Su nulidad es la dimensión de su <a href="apli.html#nucleo">núcleo</a>: <span class="math inline">\(\mathrm{nul}(f) = \mathrm{dim}(\mathrm{Ker}\ f) = 1\)</span>.</li>
<li>Su rango es la dimensión de su <a href="apli.html#imagen">imagen</a>: <span class="math inline">\(\mathrm{rg}(f) = \mathrm{dim}(\mathrm{Im}\ f) = 2\)</span></li>
</ul>
<hr />
</div>
<div id="th-dim-nucleo" class="section level2" number="3.11">
<h2 number="3.11"><span class="header-section-number">3.11</span> Qué dice el teorema de la dimensión para núcleo e imagen</h2>
<p>El resultado teórico que nos relaciona las dimensiones de <a href="apli.html#nucleo">núcleo</a> e <a href="apli.html#imagen">imagen</a> de una aplicación lineal <span class="math inline">\(f:V\to W\)</span>, es decir, su nulidad y su rango, es el siguiente:</p>
<blockquote>
<p><strong>Teorema de la dimensión</strong>:
Si <span class="math inline">\(f:V\to W\)</span> es una aplicación lineal, entonces</p>
<p><span class="math display">\[\mathrm{dim}(V) = \mathrm{dim}(\mathrm{Ker}\ f) + \mathrm{dim}(\mathrm{Im}\ f) = \mathrm{nul}(f) + \mathrm{rg}(f)\]</span></p>
</blockquote>
<p>Este resultado, reescrito en términos matriciales, queda como:</p>
<blockquote>
<p>Si <span class="math inline">\(A\)</span> es una matriz con <span class="math inline">\(m\)</span> filas y <span class="math inline">\(n\)</span> columnas, entonces</p>
<p><span class="math display">\[n = \mathrm{nul}(A) + \mathrm{rg}(A)\]</span></p>
</blockquote>
<hr />
<p><strong>Ejemplo</strong></p>
<p>Vamos a <em>comprobar</em> el teorema de la dimensión para las aplicaciones lineales <span class="math inline">\(f\)</span> y <span class="math inline">\(g\)</span> de <a href="apli.html#nucleo">los ejemplos anteriores</a>.</p>
<ul>
<li><p>Para <span class="math inline">\(f\)</span>:
<span class="math display">\[\begin{array}{ccccc}
\mathrm{dim}(\mathbb{R}^{3}) &amp; = &amp; \mathrm{dim}(\mathrm{Ker}\ f) &amp; + &amp; \mathrm{dim}(\mathrm{Im}\ f) \\
3 &amp; = &amp; 1 &amp; + &amp; 2 \\
\end{array}\]</span></p></li>
<li><p>Para <span class="math inline">\(g\)</span>:
<span class="math display">\[\begin{array}{ccccc}
\mathrm{dim}(\mathbb{R}^{3}) &amp; = &amp; \mathrm{dim}(\mathrm{Ker}\ g) &amp; + &amp; \mathrm{dim}(\mathrm{Im}\ g) \\
3 &amp; = &amp; 0 &amp; + &amp; 3 \\
\end{array}\]</span></p></li>
</ul>
<hr />

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ev.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="diagonalización.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Algebra_Lineal.pdf", "Algebra_Lineal.epub"],
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
