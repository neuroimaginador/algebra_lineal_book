# Espacios Vectoriales {#ev}

```{r echo = FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      results = "asis",
                      message = FALSE,
                      warning = FALSE)

set.seed(1234)
``` 

```{r}
n <- 4
vec0 <- rVector(n) * 0

unknowns <- c("x", "y", "z", "t", "u")[seq(n)]
generic_vector <- matrix(unknowns, ncol = 1)
```


<!-- You can label chapter and section titles using `{#label}` after them, e.g., we can reference Chapter \@ref(intro). If you do not manually label them, there will be automatic labels anyway, e.g., Chapter \@ref(methods). -->

Supongamos un cuerpo $\mathbb{K}$ (generalmente $\mathbb{K} = \mathbb{R}$). Consideremos un conjunto $V$ dotado de dos operaciones:

- Una operación interna, la _suma_, de forma que si $u,v\in V$ entonces su suma es $u+v\in V$.
- Una operación externa, _producto por un escalar_ de $\mathbb{K}$: si $c\in \mathbb{K}$ y $v\in V$, su producto es $c \cdot v \in V$.

Si:

- $V$ con la operación $+$ es grupo abeliano.
- El producto por un escalar verifica las propiedades distributiva ($(c+d)\cdot v = c\cdot v + d\cdot v$ y $c\cdot (u+v) = c\cdot u + c\cdot v$, para $c,d\in\mathbb{K},\,u,v\in V$), pseudoasociativa ($c\cdot(d\cdot v) = (c\cdot  d)\cdot v$ para $c,d\in\mathbb{K},\,v\in V$) y existencia de neutro ($1\in\mathbb{K}$, tal que $1\cdot v = v$ para todo $v\in V$).

Entonces a $(V, +, \cdot)$ se de denomina espacio vectorial, y a los elementos de $V$, vectores.

En este documento, nos referiremos normalmente a resultados sobre espacios vectoriales denominados _de dimensión finita_. Este concepto lo hablaremos más adelante.

__Ejemplo__
```{r}
vec <- rVector(n)
vec1 <- rVector(n)
vec2 <- 3 * vec - 2 * vec1
sistema <- cbind(vec, vec1, vec2)
```

$V=\mathbb{R}^{`r n`}$ es un espacio vectorial y `r glue_matrices(vec, latex = TRUE, ldeco = "$\\left(", rdeco = "\\right)$")` es un vector de $V$.

## Qué es un subespacio vectorial
\chaptermark{Subespacio Vectorial}

Un subconjunto de $U\subset V$ es un __subespacio vectorial__ de $V$ si la restricción de las operaciones suma y producto por un escalar a ese conjunto son operaciones cerradas.

Eso equivale a decir que la suma de dos vectores cualesquiera de $U$ debe estar en $U$, y si multplicamos por un escalar un vector de $U$, el producto vuelve a estar en $U$.

__Ejemplo__

$U = \left\{`r paste0(to_latex(generic_vector))`\in\mathbb{R}^{`r n`}: x + y - z = 0\right\}$ es un subespacio de $V=\mathbb{R}^{`r n`}$.

## Qué es un sistema de vectores linealmente independiente
\chaptermark{Independencia lineal}

Supongamos un conjunto de vectores $\{v_1,\ldots,v_n\}$. Este conjunto es __linealmente independiente__ si ninguno de los vectores se puede poner como combinación lineal de los demás vectores.

Esto es equivalente a que si tenemos una combinación lineal igualada a 0, de la forma 
$$\alpha_1 v_1 + \ldots + \alpha_n v_n = 0$$
entonces el sistema de los $v_i$ será independiente si necesariamente todos los $\alpha_i$ valen 0.

Evidentemente, cualquier sistema de vectores que incluya al vector 0 no es linealmente independiente.

__Ejemplo__

Consideremos el sistema de vectores `r glue("$\\left\\{", "[vectors_to_latex(sistema)]", "\\right\\}$", .open = "[", .close = "]")`. 

¿Cómo podemos saber si es linealmente independiente?

Comenzamos por ver que no está el vector 0. Estudiemos entonces qué pasa si escribimos una combinación lineal de los tres vectores igualada a cero:
```{r}
params <- paste0("\\alpha_{", 
                 seq(ncol(sistema)), "}")
glue("$$",
     "[write_linear_combination(sistema, vars = params)] = [to_latex(vec0)]",
     "$$",
     .open = "[", .close = "]") %>% 
  cat()
```

Esto lo podemos reescribir como un sistema de ecuaciones lineales donde las incógnitas son las $\alpha_i$. 

```{r}
glue("$$\\left\\{",
     "[str_flatten(write_system(sistema, vec0, latex = TRUE, vars = params))]\\right.",
     "$$",
     .open = "[", .close = "]") %>% 
  cat(sep = "")
```


Fijaos en que la matriz de coeficientes está formada por los vectores puestos por _columnas_.

Pueden ocurrir dos casos:

- Si el sistema es compatible _determinado_, entonces su única solución es que todos los $\alpha_i = 0$. Esto, por el comentario anterior, nos dice que el sistema será linealmente independiente.
- Si el sistema es compatible _indeterminado_, entonces admite más soluciones aparte de la trivial. Por tanto, hay una combinación lineal, donde no todos los $\alpha_i$ son nulos, y que da igual al vector 0. Eso nos indica que el sistema no es linealmente independiente.

Lo más sencillo en este caso es usar el método de Gauss para encontrar la forma escalonada de la matriz de coeficientes. Del estudio de sistemas homogéneos, sabemos el siguiente resultado, que se aplica tras tener la forma escalonada:

> Si el número de ecuaciones (filas) es menor estrictamente que el número de incógnitas (columnas), entonces el sistema es compatible indeterminado. En otro caso (mismo número de ecuaciones que de incógnitas), será compatible determinado.

Usamos entonces Gauss:
```{r}
s <- gauss_elimination(sistema, vec0)
glue_latex(
  "[glue_matrices(sistema, vec0, latex = TRUE)]",
  "\\sim",
  "[glue_matrices(s$splits, latex = TRUE, fractions = TRUE)]",
) %>% 
  cat()
```

En este caso, tenemos 2 filas no nulas y 3 incógnitas. Por lo anterior, el sistema es compatible indeterminado, tiene infinitas soluciones, y eso implica que el sistema no es linealmente independiente.

Si hubiéramos llegado a 3 ecuaciones no nulas, entonces estaríamos en la situación de un sistema compatible determinado, luego la única solución es la nula. Por lo anterior, el sistema sería linealmente independiente.

## Qué es un sistema generador y el subespacio generado por un conjunto de vectores
\chaptermark{Sistema generador} 

Consideramos un sistema de vectores $\mathcal{S} = \{v_1,\ldots,v_n\}$. El __subespacio generado__ por $\mathcal{S}$ es el conjunto de vectores que se calcula como combinaciones lineales de los de $\mathcal{S}$.

Es decir, si yo voy dando valores a unos escalares $\alpha_1,\ldots,\alpha_n$, entonces el vector $\alpha_1v_1+\ldots+\alpha_nv_n$ es combinación lineal de los de $\mathcal{S}$, luego pertenece al subespacio generado por éste.

Denotamos como $\mathcal{L}(\mathcal{S})$ al subsepacio generado por $\mathcal{S}$.

__Ejemplo__

Consideremos el sistema de vectores $\mathcal{S} = \left\{`r vectors_to_latex(cbind(vec, vec1))`\right\}$.

Entonces
```{r}
glue_latex(
  "\\mathcal{L}(\\mathcal{S}) = \\left\\{",
  "[write_linear_combination(cbind(vec, vec1), vars = params)]:\\alpha_i\\in\\mathbb{R}",
  "\\right\\}"
) %>% 
  cat()
```

Dando valores a $\alpha_1$ y $\alpha_2$ tendremos todos los vectores generados en $\mathcal{L}(\mathcal{S})$. Por ejemplo, para
```{r}
S <- cbind(vec, vec1)
scalars <- rVector(n = 2)
alpha1 <- scalars[1]
alpha2 <- scalars[2]
new_vector <- S %*% scalars
glue_latex(
  "\\alpha_1 = [alpha1],\\quad\\alpha_2 = [alpha2]",
  "\\quad\\Rightarrow\\quad",
  "\ v = [write_linear_combination(S, scalars)] = ",
  "[to_latex(new_vector)]\\in \\mathcal{L}(\\mathcal{S})"
)
```


## Cómo extraemos una base a partir de un sistema generador de un (sub)espacio vectorial {#sistgenabase}
\chaptermark{Bases}

Para cualquier espacio vectorial, o subespacio, una __base__ es un sistema de vectores que lo genera (mediante combinaciones lineales, como hemos visto antes) y que es linealmente independiente.

La __base canónica__ $\mathcal{C}$ en un espacio $\mathbb{R}^n$ es la dada por los vectores $e_i$ ($i = 1,\ldots,n$), donde $e_i$ es el vector que tiene todas sus componentes a 0 menos la $i$-ésima que vale 1.

Si tenemos un sistema generador de un (sub)espacio vectorial, siempre podremos encontrar una base, gracias al siguiente resultado:

> Todo sistema generador de un subespacio contiene un sistema linealmente independiente, que también genera el mismo subespacio.

El concepto de __dimensión__ está intrínsecamente relacionado con el de base: es el número de vectores en _cualquier_ base del espacio. Hay que tener en cuenta que todas las bases que se puedan encontrar en un mismo espacio vectorial tienen el mismo número de elementos.

Aparte, hay dos propiedades más que relacionan las bases y las propiedades de ser sistema generador o linealmente independiente. Si $n$ es la dimensión de un espacio vectorial:

- Todo sistema de vectores con más de $n$ elementos no puede ser linealmente independiente.
- Todo sistema generador de ese espacio debe tener, al menos, $n$ elementos.

Dado un sistema de vectores $S$ que se sepa que es sistema generador de un espacio o de un subespacio, la mejor estrategia es utilizar transformaciones elementales sobre $S$ para eliminar aquellos vectores que sean combinaciones lineales de los demás.

__Ejemplo__

```{r}
S <- rMatrix(n = n, m = 3)
S <- cbind(S, rowSums(S))
P <- gauss_elimination(t(S))
r <- abs(rowSums(P$U)) > 0 
bLS <- S[, 1:3]
```


Consideremos el sistema de vectores 
$$\mathcal{S} = \left\{`r vectors_to_latex(S)`\right\}$$
Vamos a encontrar un sistema de vectores que sea base de $\mathcal{L}(S)$. Para ellos, vamos a eliminar de $S$ aquellos vectores que sean combinaciones lineales de los demás. 

Esa tarea es justo la que realiza el método de Gauss con las filas de una matriz, al ponerla en forma escalonada. Si aplicamos Gauss a una matriz, las filas que acaban siendo de ceros son las que originalmente eran combinación lineal de las demás.

Por tanto, nos aprovechamos de esta propiedad para eliminar vectores linealmente dependientes. Vamos a construir la matriz $M$ resultado de poner los vectores de $S$ por filas (primer vector en primera fila, segundo en segunda fila, etc.).
```{r}
glue_latex(
  "M = [glue_matrices(t(S), latex = TRUE)]"
) %>% 
  cat()
```

Si aplicamos Gauss para encontrar la forma escalonada (omitimos los detalles intermedios):
```{r}
glue_latex(
  "[glue_matrices(t(S), latex = TRUE)] \\sim ",
  "[glue_matrices(P$splits, latex = TRUE, fractions = TRUE)]"
) %>% 
  cat()
```

Como se puede ver, tenemos que la última fila es de ceros. Por tanto, el vector original del que procede esa fila es linealmente dependiente del resto de vectores de $S$.

Si hubiéramos tenido que intercambiar filas en algún momento, habría que llevar cuenta de cada intercambio para saber a qué vector original se corresponden aquellas filas que valen 0.

Por tanto, la base del subespacio generado por $S$, que consiste en únicamente los vectores linealmente independientes de $S$, es:
```{r}
glue_latex(
  "\\mathcal{B}_{\\mathcal{L}(\\mathcal{S})} = \\left\\{",
  "[vectors_to_latex(bLS)]",
  "\\right\\}"
) %>% 
  cat()
```

## Cómo encontrar la base (y la dimensión) para un subespacio vectorial {#base}
\chaptermark{Bases de subespacios}

En muchas ocasiones, necesitaremos encontrar una base para un subespacio vectorial, puesto que con las bases tenemos mucha información adicional sobre un subespacio. Además, cada subespacio queda completamente caracterizado una vez dada su base.

Sin embargo, existen otras formas en las que podemos definir un subespacio vectorial, y necesitamos conocer cómo extraer una base de dicho subespacio, para tener una forma _estándar_ de describir los subespacios.

### Partiendo de las ecuaciones paramétricas

La primera forma escrita en que podemos definir un subespacio vectorial es mediante sus ecuaciones paramétricas, que nos indican cómo determinar las diversas componentes de cada vector ($x,y,\ldots$) a partir de unos parámetros libres $\alpha_1,\ldots,\alpha_n$.

Realmente esto es equivalente a escribir un vector genérico $v$ como combinación lineal de otros vectores. Esos otros vectores que forman la combinación lineal son, por tanto, un sistema generador del subespacio que queremos definir. Usando lo explicado en la [sección correspondiente](#sistgenabase), obtendríamos la base deseada.

__Ejemplo__

Consideremos el subespacio $U$ dado en su forma paramétrica:
```{r}
params <- c("\\alpha", "\\beta", "\\gamma", "\\delta")
str <- (write_system(S, 
                    format = 'c', vars = params) %>% 
  stringr::str_split(pattern = "\n"))[[1]] %>% 
  matrix(ncol = 1)
equals <- rep(" = ", nrow(S)) %>% matrix(ncol = 1)
glue_latex(
  "U = \\left\\{",
  "[to_latex(generic_vector)]\\in V:\\quad",
  "[glue_matrices(generic_vector, equals, str, latex = TRUE, sep = '', ldeco = '', rdeco = '')],",
  "\\alpha,\\beta,\\gamma,\\delta\\in\\mathbb{R}",
  "\\right\\}"
) %>% 
  cat()
```

En este caso, lo que debemos hacer es expresar esas ecuaciones paramétricas en forma de combinación lineal de vectores. Para ello, consideramos los coeficientes que acompañan a cada uno de los parámetros $\alpha,\beta,\gamma,\delta$.

Si lo hacemos, nos queda (ya poniéndolo en formato vectorial) que un vector $v$ pertenece a $U$ si se puede expresar como una combinación lineal de la forma:
```{r}
glue_latex("v = ",
  "[to_latex(generic_vector)] = ",
  "[write_linear_combination(S, vars = params)]"
) %>% 
  cat()
```

Es decir, $\mathcal{S} = \left\{`r vectors_to_latex(S)`\right\}$ es un sistema generador del subespacio $U$. Este proceso no nos asegura que sean vectores linealmente independientes, así que no podemos decir, de momento, que sea una base de $U$.

A partir de aquí, basta aplicar lo descrito en [la sección sobre cómo extraer una base a partir de un sistema generador](#sistgenabase).

### Partiendo de las ecuaciones cartesianas

Un subespacio vectorial puede venir definido mediante unas expresiones cartesianas que relacionan las componentes $x,y,\ldots$ entre sí.

Esas expresiones cartesianas realmente expresan un sistema de ecuaciones homogéneo cuyo conjunto solución es el propio subespacio que buscamos.

Por tanto, la forma de proceder es tomar las ecuaciones cartesianas, formar el sistema, y resolverlo. Para ello, haciendo Gauss, pasamos a forma escalonada o escalonada reducida y desde esa forma, calculamos las expresiones paramétricas del conjunto solución y aplicamos lo explicado en la sección anterior.

__Ejemplo__

```{r}
n_U <- sample(1:(n - 2), size = 1)
## Matrices aleatorias para sus cartesianas
A_U <- rMatrix(n = n_U, m = n, values = -1:3)
```

Sea el subespacio
```{r}
glue_latex("U = \\left\\{",
           "[to_latex(generic_vector)] \\in\\mathbb{R}^{[n]}:",
           "[str_flatten(write_system(A_U, vec0, latex = TRUE, format = 'c'))]",
           "\\right\\}"
) %>% 
  cat()
```

El sistema homogéneo dado por su ecuaciones cartesianas es:

```{r}
glue::glue("$$\\left\\{",
           "[str_flatten(write_system(A_U, vec0, latex = TRUE))]",
           "\\right.$$",
           .open = "[", .close = "]") %>% 
  cat()
```

Este sistema, resuelto por Gauss, nos da las siguientes expresiones paramétricas:
```{r}
genU <- solve_homogeneous(A_U)
params <- c("\\alpha", "\\beta", "\\delta", "\\gamma")
glue::glue(
  "$$",
  "[to_latex(generic_vector)] = ",
  "[write_linear_combination(genU, vars = params)]",
  "$$",
  .open = "[", .close = "]"
) %>% 
  cat()
```

A partir de aquí, ya sabemos que estos dos vectores son un sistema generador de $U$, luego podemos encontrar una base para $U$ si seguimos las explicaciones en [la sección correspondiente](#sistgenabase).

Podemos fijarnos que, en este ejemplo, ya los dos vectores son linealmente independientes, así que ya conforman una base, pero no es la situación general y conviene hacer, para estar seguros, lo mencionado en el párrafo anterior.

Luego, además, podemos saber que la dimensión de $U$ es $\mathrm{dim}(U) = 2$.

## Cómo convertir entre ecuaciones cartesianas y paramétricas de un subespacio vectorial {#param2cartesian}
\chaptermark{Ecuaciones cartesianas y paramétricas}

En la [sección anterior](#base), ya hemos visto que para pasar de ecuaciones cartesianas a paramétricas, basta con usar el método de Gauss-Jordan para resolver el sistema de ecuaciones homogéneo.

Para pasar de ecuaciones paramétricas de un subespacio a las ecuaciones cartesianas, se suele utilizar el método de _eliminación de parámetros_.

Si tenemos $m$ parámetros $\alpha_i$ ($i = 1,\ldots,m$) y el espacio es de dimensión $n > m$, entonces tendremos, a lo sumo, $n - m$ ecuaciones cartesianas. Buscamos un sistema de ecuaciones lineales homogéneo (las ecuaciones cartesianas) cuya solución, en forma paramétrica sea las ya dadas.

Para ello, comenzamos con la expresión paramétrica con una ecuación por cada coordenada cartesiana del subespacio (una expresión de $x$ en función de los $\alpha_i$, una para la $y$, etc.).

Se toma uno de los parámetros, y se despeja de alguna de las ecuaciones en las que aparece. Se sutituye en las demás ecuaciones y desechamos la ecuación de la que hemos despejado el parámetro. En esta situación, tenemos una ecuación menos y un parámetro menos.

Con el nuevo sistema de ecuaciones, repetimos el proceso anterior: seleccionar un parámetro, despejarlo de una ecuación y sustituirlo en las demás, eliminando la ecuación de la que se ha despejado.

Repetimos todo el proceso hasta que no queden parámetros que eliminar.

__Ejemplo__

Consideramos el subespacio
```{r}
params <- c("\\alpha", "\\beta", "\\gamma", "\\delta")
str <- (write_system(S, 
                    format = 'c', vars = params) %>% 
  stringr::str_split(pattern = "\n"))[[1]] %>% 
  matrix(ncol = 1)
equals <- rep(" = ", nrow(S)) %>% matrix(ncol = 1)
glue_latex(
  "U = \\left\\{",
  "[to_latex(generic_vector)]\\in V:\\quad",
  "[glue_matrices(generic_vector, equals, str, latex = TRUE, sep = '', ldeco = '', rdeco = '')],",
  "\\alpha,\\beta,\\gamma,\\delta\\in\\mathbb{R}",
  "\\right\\}"
) %>% 
  cat()
```

Vamos a aplicar el método de eliminación de los parámetros:

```{r}
L <- parametric_to_cartesian(S)
params <- c("\\alpha", "\\beta", "\\gamma", "\\delta")

for (p in seq_along(L$eq_idx[-1])) {
  
  par <- fractional(L$splits[[p]][[1]])
  eqs <- fractional(L$splits[[p]][[2]])
  
  str_p <- (write_system(par, fractions = TRUE,
                       format = 'c', 
                       vars = params) %>% 
            stringr::str_split(pattern = "\n"))[[1]] %>% 
    matrix(ncol = 1)
  
  equals <- rep(" = ", nrow(str_p)) %>% matrix(ncol = 1)
  
  str_a <- (write_system(eqs, fractions = TRUE,
                       format = 'c', 
                       vars = unknowns) %>% 
            stringr::str_split(pattern = "\n"))[[1]] %>% 
    matrix(ncol = 1)
  
  glue("- Despejamos ${params[p]}$ de la ecuación {L$eq_idx[p]}, y sustituimos en las demás, lo cual nos da:\n",
       "$${glue_matrices(str_a, equals, str_p, latex = TRUE, ldeco = '', rdeco = '', sep = '')}$$\n"
       ) %>% cat()
  cat("\n")

}

p <- length(L$eq_idx)

glue(
  "- Por último, despejando ${params[p]}$ de la ecuación {L$eq_idx[p]}, nos queda:\n"
) %>% cat()

glue_latex(
  "[write_system(L$A, zeros(nrow(L$A), 1), fractions = TRUE, latex = TRUE)]"
) %>% 
  cat()


```
que es la expresión en cartesianas del espacio $U$.

## Cómo hallar la intersección de dos subespacios vectoriales {#interseccion}
\chaptermark{Intersección de subespacios}

Si tenemos dos subespacios, $U$ y $W$ de $V$, podemos calcular su intersección, que es el conjunto de vectores que pertenecen a ambos subespacios a la vez.

> La intersección de dos subespacios es un nuevo subespacio, aunque puede suceder que la intersección sea únicamente el vector 0.

Conviene tener ambos subespacios expresados en forma de ecuaciones cartesianas. Si no estuviera así (porque solo se dé su base o, lo que es equivalente, las ecuaciones paramétricas), basta ver la sección sobre [cómo convertir de ecuaciones paramétricas a cartesianas](#param2cartesian).

Si un vector $v$ pertenece a la intersección, entonces verifica tanto las ecuaciones paramétricas de $U$ como las de $W$. Por tanto, podemos construir un sistema de ecuaciones con todas las ecuaciones de $U$ y de $W$, y la intersección $U\cap W$ será el conjunto solución de este sistema homogéneo _ampliado_.

A partir de ese sistema, ya hemos explicado [cómo encontrar la base](#base) del subespacio intersección.

__Ejemplo__

```{r}
# Definición de dos subespacios U y W
## Dimensiones
n_W <- 1#sample(1:(n - n_U), size = 1)
## Matrices aleatorias para sus cartesianas
A_W <- rMatrix(n = n_W, m = n, values = 0:3)

genW <- solve_homogeneous(A_W)
bW <- linearly_independents(genW)
dim_W <- ncol(bW)

# Calcular una base y la dimensión de:
# (a) U \cap W
A_Intersect <- rbind(A_U, A_W)
gen_Intersect <- solve_homogeneous(A_Intersect)
b_Intersect <- linearly_independents(gen_Intersect)
dim_Intersect <- ncol(b_Intersect)


```

Consideremos los subespacios siguientes:

```{r}
glue::glue("$$U = \\left\\{",
           "[to_latex(generic_vector)] \\in\\mathbb{R}^{[n]}:",
           "[str_flatten(write_system(A_U, b = zeros(n, 1), latex = TRUE, format = 'c'))]",
           "\\right\\}$$",
           .open = "[", .close = "]") %>% 
  cat()
glue::glue("$$W = \\left\\{",
           "[to_latex(generic_vector)] \\in\\mathbb{R}^{[n]}:",
           "[str_flatten(write_system(A_W, b = zeros(n, 1), latex = TRUE, format = 'c'))]",
           "\\right\\}$$",
           .open = "[", .close = "]") %>% 
  cat()

```

El subespacio $U$ ya lo hemos estudiado [antes](#base). 
Para calcular la intersección $U\cap W$, construimos un sistema de ecuaciones con todas las ecuaciones de $U$ y las de $W$. La intersección es el conjunto solución del sistema homogéneo resultante:
```{r}
glue::glue("$$\\left\\{",
           "[str_flatten(write_system(A_Intersect, b = zeros(nrow(A_Intersect), 1), latex = TRUE))]",
           "\\right.$$",
           .open = "[", .close = "]") %>% 
  cat()
```

Aplicamos lo que hemos visto [antes](#base) para estudiar este sistema.

```{r}

if (ncol(b_Intersect) > 0) {
  
params <- c("\\alpha", "\\beta", "\\delta", "\\gamma")
glue::glue(
  "Este sistema, resuelto por Gauss, nos da las siguientes expresiones paramétricas:\n",
  "$$",
  "[to_latex(generic_vector)] = ",
  "[write_linear_combination(gen_Intersect, vars = params)]",
  "$$",
  .open = "[", .close = "]"
) %>% 
  cat()
  
} else {
  
  glue::glue("Este sistema, si lo estudiamos por el método de Gauss, resulta ser compatible determinado, luego su única solución es el vector 0.") %>% 
    cat()
  
}
```

```{r}
if (ncol(b_Intersect) > 0) {
  
glue::glue(
  "Por tanto, una base de $U\\cap W$ será:\n",
  "$$",
  "\\mathcal{B}_{U\\cap W} = ",
  "\\left\\{[vectors_to_latex(b_Intersect)]\\right\\}",
  "$$",
  .open = "[", .close = "]"
) %>% 
  cat()
  
} else {
  
  glue::glue(
    "Luego:",
    "$$",
    "U\\cap W = \\{ 0 \\}",
    "$$",
    .open = "[", .close = "]"
  ) %>% 
    cat()
  
}

```

Y, así, $\mathrm{dim}(U\cap W) = `r ncol(b_Intersect)`$.


## ¿Es la unión de subespacios un subespacio?
\chaptermark{Unión de subespacios}

En general, no. La única forma en que la unión de dos subespacios sea también un subespacio es que sean iguales o que, al menos, uno de ellos sea el espacio $\{0\}$ o el total, $V$.

## Cómo hallar la suma de dos subespacios vectoriales {#suma}
\chaptermark{Suma de subespacios}

Dados dos subespacios $U$ y $W$ de $V$, se define su __suma__ $U+W$ como el conjunto de vectores que son combinación lineal de un vector de $U$ y otro de $W$.

Si, además, $U\cap W = \{0\}$ y $U+W = V$, entonces se llama __suma ortogonal__ y se denota por $U\oplus W$. Se dice entonces que $U$ es el __subespacio suplementario__ de $W$ y viceversa.

El resultado teórico esencial es el siguiente:

> Si $\mathcal{B}_U$ y $\mathcal{B}_W$ son bases de $U$ y $W$ respectivamente, entonces $\mathcal{G} = \mathcal{B}_U \cup \mathcal{B}_W$ es un sistema generador de $U+W$.

Por tanto, teniendo bases de $U$ y de $W$, lo primero será unirlas para obtener un sistema generador de la suma. Después, usaremos la [técnica para conseguir una base de un subespacio a partir de un sistema generador](#sistgenabase).

__Ejemplo__

Consideramos los mismos espacios $U$ y $W$ del ejemplo de la [sección sobre intersección](#interseccion).
```{r}
glue::glue("$$U = \\left\\{",
           "[to_latex(generic_vector)] \\in\\mathbb{R}^{[n]}:",
           "[str_flatten(write_system(A_U, b = zeros(n, 1), latex = TRUE, format = 'c'))]",
           "\\right\\}$$",
           .open = "[", .close = "]") %>% 
  cat()
glue::glue("$$W = \\left\\{",
           "[to_latex(generic_vector)] \\in\\mathbb{R}^{[n]}:",
           "[str_flatten(write_system(A_W, b = zeros(n, 1), latex = TRUE, format = 'c'))]",
           "\\right\\}$$",
           .open = "[", .close = "]") %>% 
  cat()

```

```{r}
# Hallar una base de U y W
genU <- solve_homogeneous(A_U)
bU <- linearly_independents(genU)
dim_U <- ncol(bU)

genW <- solve_homogeneous(A_W)
bW <- linearly_independents(genW)
dim_W <- ncol(bW)

# (b) U + W
gen_Sum <- cbind(bU, bW)
b_Sum <- linearly_independents(gen_Sum)
dim_Sum <- ncol(b_Sum)
```

Podemos aplicar la [técnica para conseguir una base a partir de las ecuaciones cartesianas](#base), y llegamos a las siguientes bases:
```{r}
glue::glue(
  "$$",
  "\\mathcal{B}_{U} = ",
  "\\left\\{[vectors_to_latex(bU)]\\right\\}",
  "$$",
  .open = "[", .close = "]"
) %>% 
  cat()
```

```{r}
glue::glue(
  "$$",
  "\\mathcal{B}_{W} = ",
  "\\left\\{[vectors_to_latex(bW)]\\right\\}",
  "$$",
  .open = "[", .close = "]"
) %>% 
  cat()
```

Ahora, tomando
```{r}
glue_latex(
  "\\mathcal{G} = \\mathcal{B}_{U} \\cup \\mathcal{B}_{W}",
  "\\left\\{[vectors_to_latex(cbind(bU, bW))]\\right\\}"
)
```
que es un sistema generador de la suma, podemos construir una base de $U+W$ [eliminando los vectores de $\mathcal{G}$ que sean combinaciones lineales de los demás](#sistgenabase), lo cual requiere usar el método de Gauss para obtener la forma escalonada reducida de ese sistema de vectores.

De esta forma, encontramos una base de $U+W$:
```{r}
glue::glue(
  "$$",
  "\\mathcal{B}_{U + W} = ",
  "\\left\\{[vectors_to_latex(b_Sum)]\\right\\}",
  "$$",
  .open = "[", .close = "]"
) %>% 
  cat()
```

Y, así, tenemos que $\mathrm{dim}(U+W) = `r ncol(b_Sum)`$.

## Comprobación del teorema de la dimensión
\chaptermark{Teorema de la dimensión}

Hay un resultado teórico que relaciona las dimensiones de dos subespacios $U$ y $W$ con las de su intersección y su suma:

> $\mathrm{dim}(U+W) = \mathrm{dim}(U) + \mathrm{dim}(W) - \mathrm{dim}(U\cap W)$

__Ejemplo__

Si consideramos los espacios $U$ y $W$ que hemos usado como ejemplos en [las secciones anteriores](#intersección), podemos comprobar fácilmente el teorema de la dimensión:

$$\begin{array}{ccccccc}
\mathrm{dim}(U+W) & = & \mathrm{dim}(U) & + & \mathrm{dim}(W) & - & \mathrm{dim}(U\cap V) \\
`r dim_Sum` & = & `r dim_U` & + & `r dim_W` & - & `r dim_Intersect` \\
\end{array}$$

## Cómo calcular el subespacio suplementario de uno dado
\chaptermark{Subespacio suplementario}

Como hemos comentado antes, el subespacio suplementario de un subespacio $U$ es aquel $W$ que verifica:

- $U\cap W = \{0\}$
- $U \oplus W = V$

Supongamos que tenemos una base $\mathcal{B}_U$ de $U$. Para determinar $W$, basta con que demos una forma de construir una base suya.

El primer paso será encontrar una forma _sencilla_ para la base de $U$. Realmente, queremos encontrar una base de $U$ a partir de la que ya tenemos, donde los vectores formen un sistema escalonado reducido. El método más indicado es usar Gauss-Jordan sobre la matriz que forman los vectores de $\mathcal{B}_U$ por _filas_.

Una vez que tenemos la forma escalonada reducida, nos fijamos en qué posiciones se encuentran los pivotes en esa matriz, es decir, las posiciones del primer elemento distinto de cero de cada fila.

Tomamos entonces, para formar la base de $W$, aquellos vectores de la base canónica que __no__ tengan un 1 en esas posiciones. Los vectores así determinados nos dan la base de $W$, el subespacio suplementario, pues nos aseguramos las dos propiedades mencionadas más arriba.


__Ejemplo__

```{r}
# Nuevo espacio U
A_U <- rMatrix(n = n, m = 2)
A_U <- linearly_independents(A_U)

# Gauss
P <- gauss_elimination(t(A_U), jordan = TRUE)
M <- P$U
# Pivotes
  if (nrow(M) == 1) {

    pivots_idx <- which(M != 0)[1]
    params_idx <- setdiff(seq(ncol(M)),
                          pivots_idx)

  } else {

    pivots_idx <- apply(M, 1, function(r) which(r != 0)[1])
    pivots_idx_final <- pivots_idx[!is.na(pivots_idx)]

    params_idx <- setdiff(seq(ncol(M)), pivots_idx_final)

  }

# Canónica
C <- eye(n)

# Solo aquellos vectores de los que no tienen 1 
# en las posiciones de los pivotes
bW <- C[, -pivots_idx]

```

Consideremos el subespacio $U$ cuya base es:
```{r}
glue_latex(
  "\\mathcal{B}_U = \\left\\{",
  "[vectors_to_latex(A_U)]",
  "\\right\\}"
) %>% 
  cat()
```

Si no tuviéramos su base, sino que $U$ viene dado de otra forma, [ya sabemos cómo encontrar la base](#base).

Ponemos los vectores de la base de $U$ en _filas_ y aplicamos el método de Gauss (o Gauss-Jordan) para encontrar la forma escalonada de la matriz:
```{r}
glue_latex(
  "[glue_matrices(t(A_U), latex = TRUE)]",
  "\\sim",
  "[glue_matrices(P$U, latex = TRUE, fractions = TRUE)]"
) %>% 
  cat()
```

Al inspeccionar la matriz escalonada, podemos ver que sus pivotes (primer elemento no nulo de cada fila) están en las columnas \(\{`r str_flatten(pivots_idx, collapse = ', ')`\} \).

Consideramos la base canónica
```{r}
glue_latex(
  "\\mathcal{C} = \\{e_i\\} = ",
  "\\left\\{[vectors_to_latex(C)]\\right\\}"
) %>% 
  cat()
```

Nos vamos a quedar con aquellos vectores de $\mathcal{C}$ que no tengan un 1 en las posiciones de los pivotes (\(\{`r str_flatten(pivots_idx, collapse = ', ')`\} \)). De esta forma, lo que tenemos es una base de $W$, el subespacio suplementario de $U$:
```{r}
glue_latex(
  "\\mathcal{B}_W = \\left\\{",
  "[vectors_to_latex(bW)]",
  "\\right\\}"
) %>% 
  cat()
```



## Cómo calcular las coordenadas de un vector con respecto a una base dada {#coord}
\chaptermark{Coordenadas}

Un concepto importante es el de __coordenadas__ de un vector, asociadas a una base $\mathcal{B}$ del espacio vectorial $V$.

Supongamos una base $\mathcal{B} = \{v_1,\ldots,v_n\}$ de $V$. Las coordenadas de un vector $v$ son unos escalares $\alpha_1,\ldots,\alpha_n$ tales que podemos expresar $v$ como una combinación lineal de los vectores de la base con esos coeficientes:
$$v = \alpha_1 v_1 + \cdots + \alpha_n v_n$$

Generalmente, como venimos haciendo desde el principio, estamos denotando e identificando a un vector con sus coordenadas, de forma que escribimos:
$$v = \left(
\begin{array}{c}
\alpha_1\\
\vdots\\
\alpha_n
\end{array}
\right)_{\mathcal{B}}$$

Cuando la base $\mathcal{B}$ es la canónica, no es necesario indicar el nombre de la base con respecto a la cual tomamos las coordenadas, a menos que lleve a confusión.

Dado un vector con sus coordenadas en la base canónica, ¿cómo puedo saber sus coordenadas en otra base $\mathcal{B}$? Tenemos dos vías, una que exploramos aquí y otra que veremos en [la sección siguiente](#cambiobase).

El determinar las coordenadas de un vector en una base distinta de la canónica es realmente equivalente a la resolución de un sistema de ecuaciones lineales, donde la matriz de coeficientes es la formada por los vectores de la nueva base _por columnas_. 

Lo vemos directamente con un ejemplo.

__Ejemplo__

```{r}
# Cambio de base
# Generar una base aleatoria y encontrar lo cambios a 
# y desde la canónica
repeat {
  
  B1 <- rMatrix(n = n, m = n * 4, values = -1:1)
  B1 <- linearly_independents(B1)

  if (ncol(B1) == n) break
  
}

repeat {
  
  B2 <- rMatrix(n = n, m = n * 4, values = 0:2)
  B2 <- linearly_independents(B2)

  if (ncol(B2) == n) break
  
}
# De B1 a C es trivial, es la propia B1.
# De C a B1 es su inversa.
P <- gauss_elimination(B1, eye(n), jordan = TRUE, diag1 = TRUE)

# Generar un vector aleatorio y expresarlo en las coordenadas
# de la base nueva
scalars <- matrix(sample(-2:4, size = n, replace = TRUE), ncol = 1)
v <- B1 %*% scalars
coord <- gauss_elimination(B1, v, jordan = FALSE, diag1 = FALSE)
```


Consideremos el vector $v$ dado por sus coordenadas en la base canónica \(`r glue::glue("{to_latex(v)}")`\). Consideremos también la base:

```{r}
glue::glue(
  "$$",
  "\\mathcal{B}_{1} = ",
  "\\left\\{[vectors_to_latex(B1)]\\right\\}",
  "$$",
  .open = "[", .close = "]"
) %>% 
  cat()
```


```{r}
params <- letters[seq(ncol(B1))]
str <- c("$", str_flatten(params, ", "), "$") %>% str_flatten()
```

Unos escalares `r str` serán las coordenadas de $v$ en la base $\mathcal{B}_1$ si se verifica:

```{r}
glue::glue(
  "$$",
  "[to_latex(v)] = [write_linear_combination(B1, vars = params)]",
  "$$",
  .open = "[", .close = "]"
  
) %>% 
  cat()
```
que se puede reescribir como el siguiente sistema de ecuaciones lineales (donde la matriz de coeficientes resulta de poner los vectores de la base $\mathcal{B}_1$ por columnas):
```{r}
glue::glue(
  "$$\\left\\{",
  "[str_flatten(write_system(B1, v, latex = TRUE, vars = params))]",
  "\\right.",
  "$$",
  .open = "[", .close = "]"
) %>% 
  cat()
```

Este sistema se puede resolver usando métodos Gaussianos, y nos da:
```{r}
glue_latex(
  " v = [to_latex(matrix(params, ncol = 1))]_{\\mathcal{B}_1} = [to_latex(scalars)]_{\\mathcal{B}_1}"
) %>% 
  cat()
```


## Cómo calcular la matriz de cambio de base entre dos bases de un mismo espacio vectorial {#cambiobase}
\chaptermark{Matriz de cambio de base}

Supongamos dos bases $\mathcal{B}_1$ y $\mathcal{B}_2$ de $V$, y que tenemos un vector $v$, expresado en coordenadas de $\mathcal{B}_1$. Nos planteamos una forma sencilla de calcular las coordenadas del mismo vector $v$ respecto a la otra base $\mathcal{B}_2$.

El principal resultado teórico en el que nos basamos (y del que alguna pincelada hemos dado en [la sección anterior](#coord)) es el que sigue:

> La transformación de las coordenadas para un mismo vector $v$ entre dos bases $\mathcal{B}_1$ y $\mathcal{B}_2$ viene dada por la siguiente expresión:
$$[v]_{\mathcal{B}_2} = A [v]_{\mathcal{B}_1}$$
donde $A$ es una matriz cuadrada formada por las coordenadas de cada vector de $\mathcal{B}_1$ en la base $\mathcal{B}_2$ y $[v]_{\mathcal{B}_i}$ indica las coordenadas de $v$ en la base $\mathcal{B}_i$.

_Notación_: A la matriz de cambio entre la base $\mathcal{B}_1$ y $\mathcal{B}_2$, se suele denotar por $P_{\mathcal{B}_1 \to \mathcal{B}_2}$.

Para calcular $P_{\mathcal{B}_1 \to \mathcal{B}_2}$, para cada vector de $\mathcal{B}_1$ vamos a encontrar sus coordenadas en la base $\mathcal{B}_2$. 

Siguiendo las explicaciones acerca de [cómo calcular coordenadas de un vector respecto de una base](#coord), queremos expresar cada $v_i$ como combinación lineal de los $v_i'$:
$$v_i = a_{1,i}v_1'+\ldots+a_{n,i}v_n'\quad\,\,\ i = 1,\ldots,n$$

En este caso, los valores $a_{1,i},\ldots,a_{1,n}$ son las coordenadas de $v_i$ en la base $\mathcal{B}_2$, y podemos escribir, para todo $i=1,\ldots,n$:
$$[v_i]_{\mathcal{B}_2} = \left(\begin{array}{c}
a_{1,i}\\
\vdots\\
a_{n,i}
\end{array}\right)$$

Según el resultado anterior, la matriz de cambio de base $A=P_{\mathcal{B}_1 \to \mathcal{B}_2}$ tendrá por columnas estas coordenadas previamente calculadas:
$$A = ([v_1]_{\mathcal{B}_2}|\ldots|[v_n]_{\mathcal{B}_2})$$

<!-- Esto nos da una serie de $n$ sistemas de ecuaciones, y, si consideramos su matriz de coeficientes, resulta ser que son los vectores $v_i'$ de $\mathcal{B}_2$ puestos por columnas, mientras que el primer término, en este caso, es el vector $i$-ésimo de $\mathcal{B}_1$ puesto también en columna. -->

Llamemos $B_1 = (v_1|v_2|\ldots|v_n)$ y $B_2 = (v_1'|v_2'|\ldots|v_n')$ a las dos matrices que resultan de poner los vectores de las dos bases que tenemos, en forma de columna.

Entonces, resulta que la combinación lineal de más arriba que relaciona un $v_i$ con los vectores de $\mathcal{B}_2$ mediante sus coordenadas se puede reescribir como:
$$v_i = B_2\ [v_i]_{\mathcal{B}_2}$$

Si vamos concatenando los $v_i$ en la izquierda, hasta formar la matriz $B_1$, en la derecha debemos ir haciendo lo mismo con sus coordenadas en la base $\mathcal{B}_2$, y entonces tenemos:
$$(v_1|v_2|\ldots|v_n) = B_2\  ([v_1]_{\mathcal{B}_2}|[v_2]_{\mathcal{B}_2}\ldots|[v_n]_{\mathcal{B}_2})$$
es decir,
$$B_1 = B_2\ P_{\mathcal{B}_1\to\mathcal{B}_2}$$

Como nos interesa una forma fácil de calcular $P_{\mathcal{B}_1\to\mathcal{B}_2}$, podemos despejarla de la expresión anterior, luego tenemos $P_{\mathcal{B}_1\to\mathcal{B}_2} = B_2^{-1}\ B_1$.

El método práctico para calcular esta matriz de cambio de base, por tanto, será usar Gauss-Jordan, comenzando por la matriz $(B_2|B_1)$ hasta dejarla en la forma $(I_n|A)$. En ese momento, en la derecha, tendremos $A=P_{\mathcal{B}_1\to\mathcal{B}_2}$.

Una vez que tenemos determinada la matriz $A = P_{\mathcal{B}_1\to\mathcal{B}_2}$ que nos proporciona el cambio de base entre $\mathcal{B}_1$ y $\mathcal{B}_2$, el cambio inverso, es decir, entre $\mathcal{B}_2$ y $\mathcal{B}_1$, tiene como matriz asociada $A^{-1}$. Recordemos que la inversa de una matriz $A$ se puede calcular mediante el método de Gauss-Jordan, comenzando por $(A|I_n)$ y reduciéndola a la forma $(I_n|A^{-1})$.

__Caso particular: Cambio de base a y desde la base canónica__

Supongamos que una de las bases, por ejemplo $\mathcal{B}_2 = \mathcal{C}$ es la base canónica. La matriz que forman sus vectores por columna en este caso sería $B_2 = I_n$, la identidad.

Aplicando lo desarrollado, tendríamos que la matriz de cambio de base de $\mathcal{B}_1$ a la canónica es:
$P_{\mathcal{B}_1\to\mathcal{C}} = P_{\mathcal{B}_1\to\mathcal{B}_2} = B_2^{-1}\ B_1 = I_n \ B_1 = B_1$.

Y entonces $P_{\mathcal{C}\to\mathcal{B}_1} = P_{\mathcal{B}_2\to\mathcal{B}_1} = B_1^{-1}\ B_2 = B_1^{-1}\ I_n = B_1^{-1}$.

__Ejemplo__

Consideremos dos bases:
```{r}
glue::glue(
  "$$",
  "\\mathcal{B}_{1} = ",
  "\\left\\{[vectors_to_latex(B1)]\\right\\}",
  "$$",
  .open = "[", .close = "]"
) %>% 
  cat()

glue::glue(
  "$$",
  "\\mathcal{B}_{2} = ",
  "\\left\\{[vectors_to_latex(B2)]\\right\\}",
  "$$",
  .open = "[", .close = "]"
) %>% 
  cat()

```

Vamos a hallar la matriz del cambio de base entre ambas bases, en ambos sentidos.

Comenzamos por hallar la matriz $A$ de cambio de base de $\mathcal{B}_1$ a $\mathcal{B}_2$.

Construimos las matrices que tienen los vectores de $\mathcal{B}_1$ y $\mathcal{B}_2$ por columnas:
```{r}
glue_latex(
  "B_1 = ",
  "[glue_matrices(B1, latex = TRUE)]"
) %>% 
  cat()

glue_latex(
  "B_2 = ",
  "[glue_matrices(B2, latex = TRUE)]"
) %>% 
  cat()
```

Como se ha mencionado antes, para hallar $A$, podemos hacer Gauss-Jordan sobre $(B_2|B_1)$ hasta llegar a $(I_n|A)$:
```{r}
P <- gauss_elimination(B2, B1, 
                       jordan = TRUE, diag1 = TRUE)
glue_latex(
  "[glue_matrices(B2, B1, latex = TRUE)]",
  "\\sim",
  "[glue_matrices(P$splits, latex = TRUE, fractions = TRUE)]"
) %>% 
  cat()
```

Luego 
```{r}
glue_latex(
  "P_{\\mathcal{B}_1\\to\\mathcal{B}_2} = ",
  "[glue_matrices(P$splits[[2]], latex = TRUE, fractions = TRUE)]"
) %>% 
  cat()
```

Para el camino contrario, pasar de coordenadas en $\mathcal{B}_2$ a coordenadas en $\mathcal{B}_1$, hacemos la inversa de la matriz anterior (aunque podríamos haber aplicado el mismo razonamiento inicial):
```{r}
A <- P$splits[[2]]
I <- eye(n)
R <- gauss_elimination(A, I, 
                       jordan = TRUE, diag1 = TRUE)
glue_latex(
  "[glue_matrices(A, I, latex = TRUE, fractions = TRUE)]",
  "\\sim",
  "[glue_matrices(R$splits, latex = TRUE, fractions = TRUE)]"
) %>% 
  cat()
```

De esta forma 
```{r}
invA <- R$splits[[2]]
glue_latex(
  "P_{\\mathcal{B}_2\\to\\mathcal{B}_1} = ",
  "[glue_matrices(R$splits[[2]], latex = TRUE, fractions = TRUE)]"
) %>% 
  cat()
```

Para completar el ejemplo, vemos el cambio de base entre $\mathcal{B}_1$ y $\mathcal{C}$:
```{r}
glue_latex(
  "P_{\\mathcal{B}_1\\to\\mathcal{C}} = B_1 = ",
  "[glue_matrices(B1, latex = TRUE)]"
) %>% 
  cat()
```

Y entre $\mathcal{C}$ y $\mathcal{B}_1$ (calculando la inversa de $B_1$ usando Gauss-Jordan):
```{r}
glue_latex(
  "P_{\\mathcal{C}\\to\\mathcal{B}_1} = B_1^{-1} = ",
  "[glue_matrices(solve(B1), latex = TRUE, fractions = TRUE)]"
) %>% 
  cat()
```
